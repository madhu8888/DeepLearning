{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 5.3 Luong’s multiplicative attention .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovnhyIOsI7v4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e29f677-fa81-4d14-a6ce-19f5c5413d54"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5ygkMcBOV64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOY-uMuYG0Ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40d46f22-9284-489f-a5b6-67484998d482"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xefePT1HHCy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence_english(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "  \n",
        "def preprocess_sentence_hindi(w):\n",
        "    w = unicode_to_ascii(w.strip())\n",
        "\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmC0oAtCHMHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1887c10-12d4-425b-84e7-6bb9e0fa9ee5"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQjSZrjYHPur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "dabc35ef-370b-4d67-a7b7-43107706c941"
      },
      "source": [
        "PATH = \"/content/drive/My Drive/Colab Notebooks/Hindi_English_Truncated_Corpus.csv\"\n",
        "data = pd.read_csv(PATH)\n",
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ...                                     hindi_sentence\n",
              "0        ted  ...  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
              "1        ted  ...  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n",
              "2  indic2012  ...   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YGY6Kw-Hi3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c760e8dc-1596-4125-caad-9ef2d4d05faf"
      },
      "source": [
        "print(data['english_sentence'].count())\n",
        "print(data['hindi_sentence'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127605\n",
            "127607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp8648auHmYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "75b27623-4d50-40ca-edf1-9fb0effde392"
      },
      "source": [
        "data = data[data['english_sentence'].map(type) == str]\n",
        "data = data[data['hindi_sentence'].map(type) == str]\n",
        "data = data[data['english_sentence'].map(len) > 0]\n",
        "data = data[data['hindi_sentence'].map(len) > 0]\n",
        "\n",
        "print(data['english_sentence'].count())\n",
        "print(data['hindi_sentence'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127605\n",
            "127605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBa0-HHLHqVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"token_size_en\"] = data[\"english_sentence\"].apply(lambda x: len(x.split(' ')))\n",
        "data[\"token_size_hn\"] = data[\"hindi_sentence\"].apply(lambda x: len(x.split(' ')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwIIM2AHuNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.loc[data['token_size_hn'] < 22].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mElF76laIB_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['english_sentence'] = data['english_sentence'].apply(preprocess_sentence_english)\n",
        "data['hindi_sentence'] = data['hindi_sentence'].apply(preprocess_sentence_hindi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWfMQ-v4INRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0f6efc45-f449-43a8-c811-f5ed54ad8acf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>token_size_en</th>\n",
              "      <th>token_size_hn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; politicians do not have permission to ...</td>\n",
              "      <td>&lt;start&gt; राजनीतिजञो क पास जो कारय करना चाहिए , ...</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; i d like to tell you about one such ch...</td>\n",
              "      <td>&lt;start&gt; मई आपको ऐस ही एक बचच क बार म बताना चाह...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>&lt;start&gt; this percentage is even greater than t...</td>\n",
              "      <td>&lt;start&gt; यह परतिशत भारत म हिनदओ परतिशत स अधिक ह...</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; what we really mean is that they re ba...</td>\n",
              "      <td>&lt;start&gt; हम य नही कहना चाहत कि वो धयान नही द पा...</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>&lt;start&gt; . the ending portion of these vedas is...</td>\n",
              "      <td>&lt;start&gt; इनही वदो का अतिम भाग उपनिषद कहलाता ह। ...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ... token_size_hn\n",
              "0        ted  ...            14\n",
              "1        ted  ...            11\n",
              "2  indic2012  ...             9\n",
              "3        ted  ...            11\n",
              "4  indic2012  ...             8\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24BmX8HNIRLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = data['english_sentence'].values.tolist()\n",
        "hn = data['hindi_sentence'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hHrujFPIVI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "756a101a-9097-48be-9517-295dad2e20bc"
      },
      "source": [
        "len(en),len(hn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90799, 90799)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Dd7bX1IYPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bc9682a2-f967-4fff-b3c1-b31e6abc734a"
      },
      "source": [
        "en[-1],hn[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> they ve just won four government contracts to build off their ambulances , <end>',\n",
              " '<start> हाल ही म उनह सरकारी ठका मिला ह करीब सौ नई अमबलनस बनान का , <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzY3O0N3IbrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a-tUg5VIgH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_fnwNQIkrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(num_examples):\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang = data['hindi_sentence'].values.tolist()[:num_examples],data['english_sentence'].values.tolist()[:num_examples]\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7RivYPFIqVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(35000)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuV5o-GtIujF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9f07a40f-c070-4fd6-d5cb-fcbf50fda27c"
      },
      "source": [
        "print(max_length_inp,max_length_targ)\n",
        "print(len(input_tensor),target_tensor[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48 31\n",
            "35000 [[   1 7745    4  109   29  197   92  106    7   52   36   16 1806   19\n",
            "     3    5    2    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   1 1404  112  176   23   14  217    4   51    6 1129 2600    7    2\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFPJaPKXIyw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "231c4e57-0fa4-4936-d813-aae8625fdf50"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000 28000 7000 7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTV-gGRxI2fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y36cGaCoI6sK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "61f0ea18-fef4-478a-f670-5d4c879324c5"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "2932 ----> technical\n",
            "2013 ----> note\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "2294 ----> तकनीकी\n",
            "3792 ----> नोट\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgwc5F_FI-9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBubQo-EJDbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f103ba84-68e0-45d6-e33d-a92de3ace32e"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 48]), TensorShape([64, 31]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSUVabGvJG2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVel38wrJK_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a12f6b21-d22d-41b2-ca01-3a5d9e85bb13"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 48, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmmctLUirAR8",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention?version=nightly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVxvb57mNe34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(LuongAttention, self).__init__()\n",
        "    self.Wa = tf.keras.layers.Dense(units)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    self.Wa = tf.keras.layers.Dense(units)\n",
        "    score1 = self.Wa(query)\n",
        "    #print(score1.shape)\n",
        "    #print(values.shape)\n",
        "    query_with_time_axis = tf.expand_dims(score1, 1)\n",
        "    score = query_with_time_axis * values\n",
        "    score = tf.reduce_sum(score, axis=2)\n",
        "    score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    # self.wa = tf.keras.layers.Dense(256)\n",
        "    # score = tf.matmul(query, self.wa(\n",
        "    #              values), transpose_b=True)\n",
        "    #attention_weights = tf.nn.softmax(score, axis=2)\n",
        "\n",
        "    #     # context vector c_t is the weighted average sum of encoder output\n",
        "    #context_vector = tf.matmul(attention_weights, values)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    #query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # inner product, score shape == (batch_size, max_length, 1)\n",
        "    # print(query_with_time_axis.shape)\n",
        "    # print(values.shape)\n",
        "    # score = query_with_time_axis * values \n",
        "    # score = tf.reduce_sum(score, axis=2)\n",
        "    # score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # # attention_weights shape == (batch_size, max_length, 1)\n",
        "    # attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    # context_vector = attention_weights * values\n",
        "    # context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    # return context_vector, attention_weights\n",
        "\n",
        "\n",
        "    ###########################################################\n",
        "    # def __init__(self,units):\n",
        "    #     super(LuongAttention, self).__init__()\n",
        "    #     self.wa = tf.keras.layers.Dense(units)\n",
        "\n",
        "\n",
        "\n",
        "       # if attention_func == 'general':\n",
        "            # General score function\n",
        "\n",
        "        # elif attention_func == 'concat':\n",
        "        #     # Concat score function\n",
        "        #     self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
        "        #     self.va = tf.keras.layers.Dense(1)\n",
        "\n",
        "    # def call(self, query, values):\n",
        "    #     self.wa = tf.keras.layers.Dense(1024)\n",
        "\n",
        "    #     query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    #     print(query_with_time_axis.shape)\n",
        "    #     score = tf.matmul(query, self.wa(\n",
        "    #             values), transpose_b=True)\n",
        "    #     #score = \n",
        "    #     print(score)\n",
        "        \n",
        "    #     # alignment a_t = softmax(score)\n",
        "    #     attention_weights = tf.nn.softmax(score, axis=2)\n",
        "\n",
        "    #     # context vector c_t is the weighted average sum of encoder output\n",
        "    #     context_vector = tf.matmul(attention_weights, values)\n",
        "\n",
        "    #     return context_vector, attention_weights\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "    #     def call(self, query, values):\n",
        "    # # query hidden state shape == (batch_size, hidden size)\n",
        "    # # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # # values shape == (batch_size, max_len, hidden size)\n",
        "    # # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    # query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # # inner product, score shape == (batch_size, max_length, 1)\n",
        "    # score = query_with_time_axis * values\n",
        "    # score = tf.reduce_sum(score, axis=2)\n",
        "    # score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # # attention_weights shape == (batch_size, max_length, 1)\n",
        "    # attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    # context_vector = attention_weights * values\n",
        "    # context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    # return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def __init__(self, rnn_size, attention_func):\n",
        "    #     super(LuongAttention, self).__init__()\n",
        "    #     self.attention_func = attention_func\n",
        "\n",
        "    #     if attention_func not in ['dot', 'general', 'concat']:\n",
        "    #         raise ValueError(\n",
        "    #             'Unknown attention score function! Must be either dot, general or concat.')\n",
        "\n",
        "    #     if attention_func == 'general':\n",
        "    #         # General score function\n",
        "    #         self.wa = tf.keras.layers.Dense(rnn_size)\n",
        "    #     elif attention_func == 'concat':\n",
        "    #         # Concat score function\n",
        "    #         self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
        "    #         self.va = tf.keras.layers.Dense(1)\n",
        "\n",
        "    # def call(self, decoder_output, encoder_output):\n",
        "    #     if self.attention_func == 'dot':\n",
        "    #         # Dot score function: decoder_output (dot) encoder_output\n",
        "    #         # decoder_output has shape: (batch_size, 1, rnn_size)\n",
        "    #         # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
        "    #         # => score has shape: (batch_size, 1, max_len)\n",
        "    #         score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
        "    #     elif self.attention_func == 'general':\n",
        "    #         # General score function: decoder_output (dot) (Wa (dot) encoder_output)\n",
        "    #         # decoder_output has shape: (batch_size, 1, rnn_size)\n",
        "    #         # encoder_output has shape: (batch_size, max_len, rnn_size)\n",
        "    #         # => score has shape: (batch_size, 1, max_len)\n",
        "    #         score = tf.matmul(decoder_output, self.wa(\n",
        "    #             encoder_output), transpose_b=True)\n",
        "    #     elif self.attention_func == 'concat':\n",
        "    #         # Concat score function: va (dot) tanh(Wa (dot) concat(decoder_output + encoder_output))\n",
        "    #         # Decoder output must be broadcasted to encoder output's shape first\n",
        "    #         decoder_output = tf.tile(\n",
        "    #             decoder_output, [1, encoder_output.shape[1], 1])\n",
        "\n",
        "    #         # Concat => Wa => va\n",
        "    #         # (batch_size, max_len, 2 * rnn_size) => (batch_size, max_len, rnn_size) => (batch_size, max_len, 1)\n",
        "    #         score = self.va(\n",
        "    #             self.wa(tf.concat((decoder_output, encoder_output), axis=-1)))\n",
        "\n",
        "    #         # Transpose score vector to have the same shape as other two above\n",
        "    #         # (batch_size, max_len, 1) => (batch_size, 1, max_len)\n",
        "    #         score = tf.transpose(score, [0, 2, 1])\n",
        "\n",
        "    #     # alignment a_t = softmax(score)\n",
        "    #     alignment = tf.nn.softmax(score, axis=2)\n",
        "\n",
        "    #     # context vector c_t is the weighted average sum of encoder output\n",
        "    #     context = tf.matmul(alignment, encoder_output)\n",
        "\n",
        "    #     return context, alignment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeG8p0PBOHdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1d0d5a4e-b08f-4a19-aa75-9e0a21c55fde"
      },
      "source": [
        "attention_layer = LuongAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKa093lUkG5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = LuongAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUOWm0x1Aaxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "972b4876-06e7-4042-c19c-db59fc23cf77"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 27722)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NMMEDL3AoGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dycnsE6EApzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipsFUifAtsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43eB0hINA1k4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "44ad8c3a-f09d-49ff-b5a8-be3972306245"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.0116\n",
            "Epoch 1 Batch 100 Loss 2.8261\n",
            "Epoch 1 Batch 200 Loss 2.4319\n",
            "Epoch 1 Batch 300 Loss 2.3760\n",
            "Epoch 1 Batch 400 Loss 2.4044\n",
            "Epoch 1 Loss 2.5772\n",
            "Time taken for 1 epoch 293.792986869812 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.1356\n",
            "Epoch 2 Batch 100 Loss 2.2390\n",
            "Epoch 2 Batch 200 Loss 2.4158\n",
            "Epoch 2 Batch 300 Loss 2.4533\n",
            "Epoch 2 Batch 400 Loss 2.2619\n",
            "Epoch 2 Loss 2.2625\n",
            "Time taken for 1 epoch 292.53888177871704 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.3400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-fa5128338d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-e1d721d7f787>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, targ, enc_hidden)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     assert all(isinstance(g, (ops.Tensor, ops.IndexedSlices))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1024,27722] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:AddN]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjNNJhzOD0Ni",
        "colab_type": "text"
      },
      "source": [
        "I got OOM error after 2 or 3 epochs but it sometimes ran for 3-4 epochs and then gave this error , so i proceeded with less training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_gB6Ok6R_88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence_english(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQHnkC7wSB0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ_I1Y0oSGCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNT87JoBSJw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93eff832-3714-47fb-c7c0-33c436dcf86f"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4889f9d2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raqbAyMDSNxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "0b30d79d-e2c2-417e-9bb7-3c49b81b64a0"
      },
      "source": [
        "translate('home')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> home <end>\n",
            "Predicted translation: यह <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzSa7U6USR0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "9e2355f0-f058-4293-e4d3-b6b047e35e30"
      },
      "source": [
        "translate(' phone')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> phone <end>\n",
            "Predicted translation: (हसी) <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfHmCpAlSciC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "97faf3f6-10e3-4691-d8e2-395cc02d1e10"
      },
      "source": [
        "translate('door')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> door <end>\n",
            "Predicted translation: और इस परकार <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdySdt2JEW3T",
        "colab_type": "text"
      },
      "source": [
        "**Questions and answers**\n",
        "\n",
        "1. Do you see qualitative differences in the attention weights between different attention mechanisms?\n",
        "  \n",
        "  Ans: The model's performance is almost same but there is quantitative difference between attention weights. Attention weights are calculated by applying softmax on attention score which is calculated differently in all the three methods. We used 3 additional weight parameters while calculating scores in Bahdanau , 2 in Luong and no additional weights in dot product ateention mechanism.\n",
        "\n",
        "2. Do you think that the model attends to the correct tokens in the input language? (if you understand both languages)\n",
        "\n",
        "  Ans: In Bahdanau and dot product the model did attend to correct tokens but in case of luong it did not gave me correct results. It could be because of the less training due to OOM error which I frequently got during training.\n",
        "\n",
        "3. Which parts of the sentence are used as a token? Each character, each word, or are some words split up?\n",
        "\n",
        "  Ans: Punctuations are removed from the sequence and after that each word is considered as a token and is mapped to an ID. \n",
        "\n",
        "4. Do the same tokens in different language have the same ID?\n",
        "\n",
        "  Ans: No the same tokens in differnt laguages do not have same ID as the come from different dictionaries.\n",
        "\n",
        "5. What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state?\n",
        "(for the architecture used in the tutorial)\n",
        "\n",
        "  Ans: The encoder outputs are discarded and only the hidden or internal states are passed as initial inputs to the decoder.\n",
        "\n",
        "6. Is the decoder attending to all previous positions, including the previous decoder predictions?\n",
        "\n",
        "  Ans: During training it gets input from previous timestamps.\n",
        "During the inference phase, we pass the predicted output from the previous time step as the input to the decoder along with the hidden states.\n",
        "\n",
        "7. Does the Encoder output change in different decoding steps?\n",
        "\n",
        "  Ans: No, the encoder output does not change in different decoding steps. \n",
        "\n",
        "8. Does the context vector change in different decoding steps?\n",
        "\n",
        "  Ans: yes with help of weights in decoding steps.\n",
        "\n",
        "9. The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?\n",
        "\n",
        "  Ans: Teacher forcing algorithm trains decoder by supplying actual output of the previous timestamp instead of the predicted output from the previous time as inputs during training. So, it depends on previous timestamps and hence i don't think paralleisation is possible.\n",
        "\n",
        "10. Why is a mask applied to the loss function?\n",
        "\n",
        "  Ans: This I didn't understand. :(\n"
      ]
    }
  ]
}