{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task5.2 dotproductattention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbYcg1RKBhN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0c05f56-2c45-4a48-de4a-082b0b075251"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHXuP2yVBkB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf62b080-8286-4441-d7a8-0f3a1387f6af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj5BpJbGBoOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence_english(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "  \n",
        "def preprocess_sentence_hindi(w):\n",
        "    w = unicode_to_ascii(w.strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "#     w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLEjWtRPBwZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e24de7b-4d9e-4401-f82b-a27dc1b5006f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVWONYx-CDUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "960a8396-6286-4f0c-8599-31bb11467b1c"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBS-OjOqCMDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "aebdbbe5-ff19-4064-a243-8858325092b6"
      },
      "source": [
        "PATH = \"/content/drive/My Drive/Colab Notebooks/Hindi_English_Truncated_Corpus.csv\"\n",
        "data = pd.read_csv(PATH)\n",
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ...                                     hindi_sentence\n",
              "0        ted  ...  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
              "1        ted  ...  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n",
              "2  indic2012  ...   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiH9E1djCQdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3fd1f572-03a2-4569-b19d-82895b765c46"
      },
      "source": [
        "print(data['english_sentence'].count())\n",
        "print(data['hindi_sentence'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127605\n",
            "127607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdlpnam-CUXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "96a0c65e-e088-480a-d91b-594eba7e4570"
      },
      "source": [
        "data = data[data['english_sentence'].map(type) == str]\n",
        "data = data[data['hindi_sentence'].map(type) == str]\n",
        "data = data[data['english_sentence'].map(len) > 0]\n",
        "data = data[data['hindi_sentence'].map(len) > 0]\n",
        "\n",
        "print(data['english_sentence'].count())\n",
        "print(data['hindi_sentence'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127605\n",
            "127605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aCZCdGrCYUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"token_size_en\"] = data[\"english_sentence\"].apply(lambda x: len(x.split(' ')))\n",
        "data[\"token_size_hn\"] = data[\"hindi_sentence\"].apply(lambda x: len(x.split(' ')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV7JZHVJCcuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.loc[data['token_size_hn'] < 22].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9q781SmCgeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5297865e-2557-4f3a-c007-4fdd37fbb8c9"
      },
      "source": [
        "int(data['english_sentence'].count())\n",
        "print(data['hindi_sentence'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYfohAmWCkSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['english_sentence'] = data['english_sentence'].apply(preprocess_sentence_english)\n",
        "data['hindi_sentence'] = data['hindi_sentence'].apply(preprocess_sentence_hindi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zurR0_fCpAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a753570-9ca7-4e5c-ea72-b95f2965df70"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>token_size_en</th>\n",
              "      <th>token_size_hn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; politicians do not have permission to ...</td>\n",
              "      <td>&lt;start&gt; राजनीतिजञो क पास जो कारय करना चाहिए , ...</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; i d like to tell you about one such ch...</td>\n",
              "      <td>&lt;start&gt; मई आपको ऐस ही एक बचच क बार म बताना चाह...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>&lt;start&gt; this percentage is even greater than t...</td>\n",
              "      <td>&lt;start&gt; यह परतिशत भारत म हिनदओ परतिशत स अधिक ह...</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; what we really mean is that they re ba...</td>\n",
              "      <td>&lt;start&gt; हम य नही कहना चाहत कि वो धयान नही द पा...</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>&lt;start&gt; . the ending portion of these vedas is...</td>\n",
              "      <td>&lt;start&gt; इनही वदो का अतिम भाग उपनिषद कहलाता ह। ...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ... token_size_hn\n",
              "0        ted  ...            14\n",
              "1        ted  ...            11\n",
              "2  indic2012  ...             9\n",
              "3        ted  ...            11\n",
              "4  indic2012  ...             8\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIaTVxdBCs3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en = data['english_sentence'].values.tolist()\n",
        "hn = data['hindi_sentence'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR9vuCMACwo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d26af6d-3946-432f-e279-c3d6e4064a83"
      },
      "source": [
        "len(en),len(hn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90799, 90799)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8uFmYlNCz4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3bd3041-2958-46f6-98ec-bd2e7e92701d"
      },
      "source": [
        "en[-1],hn[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> they ve just won four government contracts to build off their ambulances , <end>',\n",
              " '<start> हाल ही म उनह सरकारी ठका मिला ह करीब सौ नई अमबलनस बनान का , <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UowGnNHqC3OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wx_JlsyC6tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_bAg7j4DKRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(num_examples):\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang = data['hindi_sentence'].values.tolist()[:num_examples],data['english_sentence'].values.tolist()[:num_examples]\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdQjNyX1DNmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(35000)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrcHnVGoDRuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "87518e64-b021-44c9-f728-03ae87385617"
      },
      "source": [
        "print(max_length_inp,max_length_targ)\n",
        "print(len(input_tensor),target_tensor[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48 31\n",
            "35000 [[   1 7745    4  109   29  197   92  106    7   52   36   16 1806   19\n",
            "     3    5    2    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   1 1404  112  176   23   14  217    4   51    6 1129 2600    7    2\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaq5vnIwDVaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ee8e206-aad7-4873-baea-ebb4f4ccffea"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000 28000 7000 7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppx1qdXbDaxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4JozyJUDg5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "422ae832-6f3d-474a-f4af-150974daf87a"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "7 ----> and\n",
            "41 ----> all\n",
            "4 ----> the\n",
            "1729 ----> ship\n",
            "40 ----> can\n",
            "56 ----> do\n",
            "11 ----> is\n",
            "8 ----> to\n",
            "705 ----> dance\n",
            "7 ----> and\n",
            "3735 ----> pitch\n",
            "438 ----> along\n",
            "23 ----> with\n",
            "4 ----> the\n",
            "8071 ----> waves\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "8 ----> और\n",
            "18523 ----> जहान\n",
            "273 ----> बस\n",
            "18524 ----> लहरो\n",
            "4 ----> क\n",
            "49 ----> साथ\n",
            "11561 ----> हिचकोल\n",
            "821 ----> खान\n",
            "1777 ----> लगा।\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJab5503DiiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v3ubKuhDm0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63c9d4da-886c-45ad-b2b6-67b61647f2e3"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 48]), TensorShape([64, 31]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnmbrmkODrLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI3_T12qDuy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04926042-5294-4f0c-b058-b779521c2147"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 48, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JftVDBXxDywm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # inner product, score shape == (batch_size, max_length, 1)\n",
        "    score = query_with_time_axis * values\n",
        "    score = tf.reduce_sum(score, axis=2)\n",
        "    score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF5mG2NpD5Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "173e138c-1ca6-48ac-f234-1ef5123dc4cc"
      },
      "source": [
        "attention_layer = DotProductAttention()\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7FfnwSlEA6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = DotProductAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De6TQxc1EZUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db60a904-607e-4cd4-e0f1-150ff6797af6"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 27722)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwPiWcTOEwL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RJ9HhA8Ex0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5aGSzwME11g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDhaIL0NE7PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5944061d-6661-4f44-f150-28a72b359302"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.7868\n",
            "Epoch 1 Batch 100 Loss 1.7638\n",
            "Epoch 1 Batch 200 Loss 1.5777\n",
            "Epoch 1 Batch 300 Loss 1.7157\n",
            "Epoch 1 Batch 400 Loss 1.7492\n",
            "Epoch 1 Loss 1.7302\n",
            "Time taken for 1 epoch 226.08108282089233 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4828\n",
            "Epoch 2 Batch 100 Loss 1.4337\n",
            "Epoch 2 Batch 200 Loss 1.5999\n",
            "Epoch 2 Batch 300 Loss 1.5140\n",
            "Epoch 2 Batch 400 Loss 1.5303\n",
            "Epoch 2 Loss 1.5977\n",
            "Time taken for 1 epoch 229.47209930419922 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4358\n",
            "Epoch 3 Batch 100 Loss 1.7029\n",
            "Epoch 3 Batch 200 Loss 1.4257\n",
            "Epoch 3 Batch 300 Loss 1.4270\n",
            "Epoch 3 Batch 400 Loss 1.6410\n",
            "Epoch 3 Loss 1.4681\n",
            "Time taken for 1 epoch 226.73121881484985 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.3210\n",
            "Epoch 4 Batch 100 Loss 1.2255\n",
            "Epoch 4 Batch 200 Loss 1.3344\n",
            "Epoch 4 Batch 300 Loss 1.4368\n",
            "Epoch 4 Batch 400 Loss 1.4769\n",
            "Epoch 4 Loss 1.3352\n",
            "Time taken for 1 epoch 228.61823749542236 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.1004\n",
            "Epoch 5 Batch 100 Loss 1.3629\n",
            "Epoch 5 Batch 200 Loss 1.1708\n",
            "Epoch 5 Batch 300 Loss 1.2826\n",
            "Epoch 5 Batch 400 Loss 1.4695\n",
            "Epoch 5 Loss 1.2094\n",
            "Time taken for 1 epoch 225.8955681324005 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.0679\n",
            "Epoch 6 Batch 100 Loss 1.0968\n",
            "Epoch 6 Batch 200 Loss 1.2710\n",
            "Epoch 6 Batch 300 Loss 0.9518\n",
            "Epoch 6 Batch 400 Loss 1.0909\n",
            "Epoch 6 Loss 1.0922\n",
            "Time taken for 1 epoch 230.04573225975037 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.9965\n",
            "Epoch 7 Batch 100 Loss 0.8646\n",
            "Epoch 7 Batch 200 Loss 0.9683\n",
            "Epoch 7 Batch 300 Loss 1.1004\n",
            "Epoch 7 Batch 400 Loss 0.8974\n",
            "Epoch 7 Loss 0.9874\n",
            "Time taken for 1 epoch 226.8711700439453 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.8649\n",
            "Epoch 8 Batch 100 Loss 0.9518\n",
            "Epoch 8 Batch 200 Loss 0.9278\n",
            "Epoch 8 Batch 300 Loss 0.7779\n",
            "Epoch 8 Batch 400 Loss 0.8342\n",
            "Epoch 8 Loss 0.8940\n",
            "Time taken for 1 epoch 228.25432896614075 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.7817\n",
            "Epoch 9 Batch 100 Loss 0.8471\n",
            "Epoch 9 Batch 200 Loss 0.8251\n",
            "Epoch 9 Batch 300 Loss 0.8412\n",
            "Epoch 9 Batch 400 Loss 0.8556\n",
            "Epoch 9 Loss 0.8107\n",
            "Time taken for 1 epoch 225.93323683738708 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.6520\n",
            "Epoch 10 Batch 100 Loss 0.6615\n",
            "Epoch 10 Batch 200 Loss 0.7916\n",
            "Epoch 10 Batch 300 Loss 0.7780\n",
            "Epoch 10 Batch 400 Loss 0.7935\n",
            "Epoch 10 Loss 0.7340\n",
            "Time taken for 1 epoch 227.51610922813416 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lQIaVPbtERw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence_english(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm1gO5vltJrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z785kgNItSb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkjekWa1tWb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "512dc505-acfe-4d69-ab3d-36e12bb4f585"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0bc388da20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY4ofMSMtasp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "outputId": "27709b16-3a13-435b-93be-b21e2b607a0f"
      },
      "source": [
        "translate(' work')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> work <end>\n",
            "Predicted translation: करियर <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2351 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0u8p3pOtjs7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50195269-fbbf-4f74-e18f-db16a233bc13"
      },
      "source": [
        "translate('bottle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> bottle <end>\n",
            "Predicted translation: अकस (aks)( २००१ ) <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2309 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2408 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2406 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2407 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2309 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2408 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2406 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2407 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}