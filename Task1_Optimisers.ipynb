{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1 : Optimisers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXZ1gnWReJUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (16.0, 9.0)\n",
        "import numpy as np\n",
        "\n",
        "# Seed\n",
        "np.random.seed(1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OIpT8ZheOy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ifmd7XeQRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2eb76963-0ac7-40aa-e634-e500ca61c6b4"
      },
      "source": [
        "print('X_Train:\\t', X_train.shape)\n",
        "print('y_train:\\t', y_train.shape)\n",
        "\n",
        "print('X_test:\\t\\t', X_test.shape)\n",
        "print('y_test:\\t\\t', y_test.shape)\n",
        "\n",
        "input_shape = X_train[0].shape\n",
        "print('\\nInput Shape:\\t', input_shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_Train:\t (50000, 32, 32, 3)\n",
            "y_train:\t (50000, 1)\n",
            "X_test:\t\t (10000, 32, 32, 3)\n",
            "y_test:\t\t (10000, 1)\n",
            "\n",
            "Input Shape:\t (32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DBM_BnreZYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9OGU6QeaYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=input_shape, activation='relu'))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(units=512, activation='relu'))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dense(units=10, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "    \n",
        "    print('Model initialized. Please compile before training.')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT0FNKbziY95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Tv2GyKeelH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4c5c2b1-c010-4b39-b756-e96ddf2b90ef"
      },
      "source": [
        "model_sgd_plain = get_model()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLpi0kQe4pU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97615330-1c36-424f-eb19-43770ffdc6f0"
      },
      "source": [
        "model_sgd_plain.summary()\n",
        "sgd_plain = keras.optimizers.SGD()\n",
        "model_sgd_plain.compile(loss='sparse_categorical_crossentropy', optimizer=sgd_plain, metrics=['accuracy'])\n",
        "history_sgd_plain = model_sgd_plain.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 955,512\n",
            "Trainable params: 955,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2994 - accuracy: 0.1258 - val_loss: 2.2937 - val_accuracy: 0.1214\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.2681 - accuracy: 0.1558 - val_loss: 2.2116 - val_accuracy: 0.1760\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 2.1123 - accuracy: 0.2108 - val_loss: 2.0213 - val_accuracy: 0.2537\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9913 - accuracy: 0.2609 - val_loss: 1.9255 - val_accuracy: 0.2970\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9164 - accuracy: 0.3001 - val_loss: 1.8650 - val_accuracy: 0.3189\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.8275 - accuracy: 0.3435 - val_loss: 1.8479 - val_accuracy: 0.3529\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.7382 - accuracy: 0.3759 - val_loss: 1.6569 - val_accuracy: 0.4136\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.6509 - accuracy: 0.4073 - val_loss: 1.5755 - val_accuracy: 0.4268\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.5788 - accuracy: 0.4307 - val_loss: 1.5262 - val_accuracy: 0.4469\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.5201 - accuracy: 0.4528 - val_loss: 1.5191 - val_accuracy: 0.4395\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4646 - accuracy: 0.4743 - val_loss: 1.4530 - val_accuracy: 0.4743\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4188 - accuracy: 0.4915 - val_loss: 1.4190 - val_accuracy: 0.4899\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3695 - accuracy: 0.5096 - val_loss: 1.4808 - val_accuracy: 0.4658\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3265 - accuracy: 0.5253 - val_loss: 1.3374 - val_accuracy: 0.5189\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2939 - accuracy: 0.5365 - val_loss: 1.3067 - val_accuracy: 0.5288\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2532 - accuracy: 0.5539 - val_loss: 1.2895 - val_accuracy: 0.5447\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2122 - accuracy: 0.5700 - val_loss: 1.3540 - val_accuracy: 0.5170\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1851 - accuracy: 0.5796 - val_loss: 1.2496 - val_accuracy: 0.5631\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1447 - accuracy: 0.5962 - val_loss: 1.2698 - val_accuracy: 0.5517\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1091 - accuracy: 0.6095 - val_loss: 1.1948 - val_accuracy: 0.5808\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0798 - accuracy: 0.6199 - val_loss: 1.1978 - val_accuracy: 0.5892\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0477 - accuracy: 0.6319 - val_loss: 1.1755 - val_accuracy: 0.5902\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.0147 - accuracy: 0.6412 - val_loss: 1.2445 - val_accuracy: 0.5642\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9837 - accuracy: 0.6556 - val_loss: 1.1983 - val_accuracy: 0.5922\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9517 - accuracy: 0.6667 - val_loss: 1.2448 - val_accuracy: 0.5780\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.9187 - accuracy: 0.6777 - val_loss: 1.2542 - val_accuracy: 0.5790\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8891 - accuracy: 0.6876 - val_loss: 1.1901 - val_accuracy: 0.5942\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8586 - accuracy: 0.6998 - val_loss: 1.1773 - val_accuracy: 0.5977\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.8297 - accuracy: 0.7098 - val_loss: 1.1375 - val_accuracy: 0.6166\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7911 - accuracy: 0.7241 - val_loss: 1.2563 - val_accuracy: 0.5845\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7643 - accuracy: 0.7315 - val_loss: 1.2048 - val_accuracy: 0.6097\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7372 - accuracy: 0.7419 - val_loss: 1.1728 - val_accuracy: 0.6170\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7002 - accuracy: 0.7545 - val_loss: 1.2094 - val_accuracy: 0.6059\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6705 - accuracy: 0.7650 - val_loss: 1.2907 - val_accuracy: 0.5979\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4119 - accuracy: 0.8540 - val_loss: 1.4468 - val_accuracy: 0.6189\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3839 - accuracy: 0.8650 - val_loss: 1.6340 - val_accuracy: 0.5985\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3645 - accuracy: 0.8740 - val_loss: 1.5661 - val_accuracy: 0.5961\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3282 - accuracy: 0.8843 - val_loss: 1.7309 - val_accuracy: 0.5992\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3012 - accuracy: 0.8966 - val_loss: 1.9474 - val_accuracy: 0.5779\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2803 - accuracy: 0.9035 - val_loss: 1.7587 - val_accuracy: 0.6052\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2539 - accuracy: 0.9148 - val_loss: 1.8140 - val_accuracy: 0.6036\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.2386 - accuracy: 0.9240 - val_loss: 2.0438 - val_accuracy: 0.5789\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1915 - accuracy: 0.9367 - val_loss: 3.2674 - val_accuracy: 0.4909\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1976 - accuracy: 0.9422 - val_loss: 2.0526 - val_accuracy: 0.6141\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.1690 - accuracy: 0.9485 - val_loss: 1.9527 - val_accuracy: 0.6059\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.1394 - accuracy: 0.9616 - val_loss: 2.0846 - val_accuracy: 0.6175\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1042 - accuracy: 0.9712 - val_loss: 2.2918 - val_accuracy: 0.6194\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0502 - accuracy: 0.9868 - val_loss: 2.4821 - val_accuracy: 0.6146\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.1256 - accuracy: 0.9683 - val_loss: 2.2689 - val_accuracy: 0.6083\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0887 - accuracy: 0.9754 - val_loss: 2.2641 - val_accuracy: 0.5938\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0383 - accuracy: 0.9908 - val_loss: 2.7336 - val_accuracy: 0.6146\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0141 - accuracy: 0.9982 - val_loss: 2.8618 - val_accuracy: 0.6236\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 2.9785 - val_accuracy: 0.6248\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 3.1229 - val_accuracy: 0.6268\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.2075 - val_accuracy: 0.6277\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2870 - val_accuracy: 0.6286\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3540 - val_accuracy: 0.6268\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.4126 - val_accuracy: 0.6290\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.4734 - val_accuracy: 0.6275\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.5154 - val_accuracy: 0.6278\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.5597 - val_accuracy: 0.6277\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 9.4431e-04 - accuracy: 1.0000 - val_loss: 3.5984 - val_accuracy: 0.6287\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 8.6511e-04 - accuracy: 1.0000 - val_loss: 3.6419 - val_accuracy: 0.6276\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 7.9878e-04 - accuracy: 1.0000 - val_loss: 3.6713 - val_accuracy: 0.6280\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 7.4112e-04 - accuracy: 1.0000 - val_loss: 3.7041 - val_accuracy: 0.6285\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 6.9163e-04 - accuracy: 1.0000 - val_loss: 3.7366 - val_accuracy: 0.6280\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 6.4579e-04 - accuracy: 1.0000 - val_loss: 3.7614 - val_accuracy: 0.6273\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 6.0772e-04 - accuracy: 1.0000 - val_loss: 3.7905 - val_accuracy: 0.6277\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.7181e-04 - accuracy: 1.0000 - val_loss: 3.8168 - val_accuracy: 0.6281\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.4135e-04 - accuracy: 1.0000 - val_loss: 3.8418 - val_accuracy: 0.6278\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.1156e-04 - accuracy: 1.0000 - val_loss: 3.8656 - val_accuracy: 0.6287\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.8646e-04 - accuracy: 1.0000 - val_loss: 3.8902 - val_accuracy: 0.6281\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.6403e-04 - accuracy: 1.0000 - val_loss: 3.9106 - val_accuracy: 0.6279\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.4202e-04 - accuracy: 1.0000 - val_loss: 3.9331 - val_accuracy: 0.6280\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.2274e-04 - accuracy: 1.0000 - val_loss: 3.9535 - val_accuracy: 0.6283\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.0405e-04 - accuracy: 1.0000 - val_loss: 3.9737 - val_accuracy: 0.6286\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.8818e-04 - accuracy: 1.0000 - val_loss: 3.9923 - val_accuracy: 0.6285\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.7197e-04 - accuracy: 1.0000 - val_loss: 4.0106 - val_accuracy: 0.6282\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.5817e-04 - accuracy: 1.0000 - val_loss: 4.0287 - val_accuracy: 0.6278\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.4459e-04 - accuracy: 1.0000 - val_loss: 4.0465 - val_accuracy: 0.6282\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.3184e-04 - accuracy: 1.0000 - val_loss: 4.0598 - val_accuracy: 0.6279\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.2047e-04 - accuracy: 1.0000 - val_loss: 4.0787 - val_accuracy: 0.6284\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 3.0920e-04 - accuracy: 1.0000 - val_loss: 4.0942 - val_accuracy: 0.6278\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.9907e-04 - accuracy: 1.0000 - val_loss: 4.1107 - val_accuracy: 0.6282\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.8941e-04 - accuracy: 1.0000 - val_loss: 4.1234 - val_accuracy: 0.6282\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.8009e-04 - accuracy: 1.0000 - val_loss: 4.1373 - val_accuracy: 0.6277\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.7152e-04 - accuracy: 1.0000 - val_loss: 4.1529 - val_accuracy: 0.6277\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.6342e-04 - accuracy: 1.0000 - val_loss: 4.1661 - val_accuracy: 0.6277\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.5575e-04 - accuracy: 1.0000 - val_loss: 4.1783 - val_accuracy: 0.6275\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4856e-04 - accuracy: 1.0000 - val_loss: 4.1929 - val_accuracy: 0.6275\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4171e-04 - accuracy: 1.0000 - val_loss: 4.2046 - val_accuracy: 0.6275\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3495e-04 - accuracy: 1.0000 - val_loss: 4.2189 - val_accuracy: 0.6282\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2885e-04 - accuracy: 1.0000 - val_loss: 4.2302 - val_accuracy: 0.6280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-7Ilqde_O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_sgd_plain.save('model_sgd_plain.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iZ05CJBfFoT",
        "colab_type": "text"
      },
      "source": [
        "ADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU5IsgzRfDMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "497a5a90-6192-4fb4-b2ec-498187b761e2"
      },
      "source": [
        "model_adam = get_model()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbBZzRgfKND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5023595-9ed4-44b1-8d79-ae1a90f3a3e5"
      },
      "source": [
        "model_adam.summary()\n",
        "adam = keras.optimizers.Adam()\n",
        "model_adam.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "history_adam = model_adam.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 955,512\n",
            "Trainable params: 955,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.7982 - accuracy: 0.3234 - val_loss: 1.4484 - val_accuracy: 0.4821\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3149 - accuracy: 0.5285 - val_loss: 1.1931 - val_accuracy: 0.5759\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.1022 - accuracy: 0.6084 - val_loss: 1.0883 - val_accuracy: 0.6186\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9558 - accuracy: 0.6654 - val_loss: 1.0023 - val_accuracy: 0.6517\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8275 - accuracy: 0.7110 - val_loss: 0.8908 - val_accuracy: 0.6915\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7201 - accuracy: 0.7502 - val_loss: 0.8641 - val_accuracy: 0.7051\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6236 - accuracy: 0.7840 - val_loss: 0.8454 - val_accuracy: 0.7230\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5386 - accuracy: 0.8112 - val_loss: 0.8561 - val_accuracy: 0.7247\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4533 - accuracy: 0.8426 - val_loss: 0.8644 - val_accuracy: 0.7345\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3823 - accuracy: 0.8665 - val_loss: 0.9189 - val_accuracy: 0.7252\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3102 - accuracy: 0.8930 - val_loss: 0.9313 - val_accuracy: 0.7320\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2552 - accuracy: 0.9105 - val_loss: 1.0585 - val_accuracy: 0.7262\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2058 - accuracy: 0.9288 - val_loss: 1.1664 - val_accuracy: 0.7204\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1865 - accuracy: 0.9358 - val_loss: 1.1620 - val_accuracy: 0.7311\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1369 - accuracy: 0.9525 - val_loss: 1.3387 - val_accuracy: 0.7312\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1233 - accuracy: 0.9583 - val_loss: 1.3815 - val_accuracy: 0.7250\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1169 - accuracy: 0.9596 - val_loss: 1.5138 - val_accuracy: 0.7229\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1031 - accuracy: 0.9655 - val_loss: 1.5127 - val_accuracy: 0.7323\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0918 - accuracy: 0.9688 - val_loss: 1.5403 - val_accuracy: 0.7261\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0832 - accuracy: 0.9726 - val_loss: 1.7103 - val_accuracy: 0.7204\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0792 - accuracy: 0.9729 - val_loss: 1.7582 - val_accuracy: 0.7299\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0796 - accuracy: 0.9730 - val_loss: 1.7374 - val_accuracy: 0.7243\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0680 - accuracy: 0.9775 - val_loss: 1.7397 - val_accuracy: 0.7291\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0808 - accuracy: 0.9728 - val_loss: 1.7111 - val_accuracy: 0.7303\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0568 - accuracy: 0.9809 - val_loss: 1.8492 - val_accuracy: 0.7178\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0699 - accuracy: 0.9762 - val_loss: 1.8773 - val_accuracy: 0.7308\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 2.0491 - val_accuracy: 0.7162\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0788 - accuracy: 0.9745 - val_loss: 1.8455 - val_accuracy: 0.7218\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 2.0513 - val_accuracy: 0.7269\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0535 - accuracy: 0.9830 - val_loss: 2.0243 - val_accuracy: 0.7179\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 2.1676 - val_accuracy: 0.7135\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 1.9897 - val_accuracy: 0.7139\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0595 - accuracy: 0.9806 - val_loss: 1.9918 - val_accuracy: 0.7217\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0608 - accuracy: 0.9806 - val_loss: 1.8768 - val_accuracy: 0.7275\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 1.9513 - val_accuracy: 0.7264\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 2.1363 - val_accuracy: 0.7227\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 2.1766 - val_accuracy: 0.7175\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 2.0042 - val_accuracy: 0.7276\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 2.0653 - val_accuracy: 0.7273\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 1.9830 - val_accuracy: 0.7268\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 2.1067 - val_accuracy: 0.7186\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 2.1141 - val_accuracy: 0.7266\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 2.0287 - val_accuracy: 0.7305\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 2.0015 - val_accuracy: 0.7306\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 2.1222 - val_accuracy: 0.7299\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0404 - accuracy: 0.9873 - val_loss: 2.1568 - val_accuracy: 0.7231\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 2.2040 - val_accuracy: 0.7246\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 2.0879 - val_accuracy: 0.7156\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 2.1891 - val_accuracy: 0.7251\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 1.9571 - val_accuracy: 0.7249\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 2.1935 - val_accuracy: 0.7286\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 2.1198 - val_accuracy: 0.7303\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 2.2145 - val_accuracy: 0.7211\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 2.4252 - val_accuracy: 0.7254\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 2.1961 - val_accuracy: 0.7147\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 2.1957 - val_accuracy: 0.7299\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 2.1909 - val_accuracy: 0.7216\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0381 - accuracy: 0.9880 - val_loss: 2.0894 - val_accuracy: 0.7236\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 2.3192 - val_accuracy: 0.7232\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 2.1660 - val_accuracy: 0.7276\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 2.2458 - val_accuracy: 0.7252\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 2.2120 - val_accuracy: 0.7300\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 2.2301 - val_accuracy: 0.7219\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 2.2073 - val_accuracy: 0.7160\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 2.2199 - val_accuracy: 0.7301\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 2.1233 - val_accuracy: 0.7195\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 2.4229 - val_accuracy: 0.7235\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 2.1227 - val_accuracy: 0.7247\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 2.1390 - val_accuracy: 0.7297\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 2.5162 - val_accuracy: 0.7253\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0415 - accuracy: 0.9873 - val_loss: 2.1004 - val_accuracy: 0.7155\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 2.2471 - val_accuracy: 0.7279\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 2.3705 - val_accuracy: 0.7192\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 2.3562 - val_accuracy: 0.7279\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 2.3718 - val_accuracy: 0.7223\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 2.3316 - val_accuracy: 0.7205\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 2.1961 - val_accuracy: 0.7274\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 2.1708 - val_accuracy: 0.7279\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 2.3774 - val_accuracy: 0.7323\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0275 - accuracy: 0.9920 - val_loss: 2.3981 - val_accuracy: 0.7250\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 2.2367 - val_accuracy: 0.7302\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0243 - accuracy: 0.9927 - val_loss: 2.3197 - val_accuracy: 0.7269\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 2.3012 - val_accuracy: 0.7309\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 2.2634 - val_accuracy: 0.7267\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 2.1993 - val_accuracy: 0.7297\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 2.4294 - val_accuracy: 0.7265\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 2.2226 - val_accuracy: 0.7345\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 2.1865 - val_accuracy: 0.7306\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 2.3407 - val_accuracy: 0.7247\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 2.3318 - val_accuracy: 0.7288\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 2.3628 - val_accuracy: 0.7322\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 2.3681 - val_accuracy: 0.7230\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0299 - accuracy: 0.9907 - val_loss: 2.1911 - val_accuracy: 0.7337\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 2.3840 - val_accuracy: 0.7399\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 2.0416 - val_accuracy: 0.7369\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 2.2423 - val_accuracy: 0.7337\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 2.1663 - val_accuracy: 0.7298\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 2.2857 - val_accuracy: 0.7306\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 2.3198 - val_accuracy: 0.7331\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 2.4765 - val_accuracy: 0.7289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6iq8QuAfNjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adam.save('model_adam.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW0N0VV7fYHw",
        "colab_type": "text"
      },
      "source": [
        "RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6uY-JhpfVxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "982917b3-c199-40d8-fcaa-814f2013baf6"
      },
      "source": [
        "model_rms = get_model()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG31D813fdqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6215ea93-c417-4995-e911-58fcc517d49c"
      },
      "source": [
        "model_rms.summary()\n",
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model_rms.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "history_rmsprop = model_rms.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 955,512\n",
            "Trainable params: 955,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8878 - accuracy: 0.3217 - val_loss: 1.4998 - val_accuracy: 0.4581\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3956 - accuracy: 0.5084 - val_loss: 1.4360 - val_accuracy: 0.4810\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.1320 - accuracy: 0.6060 - val_loss: 1.0686 - val_accuracy: 0.6334\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.9408 - accuracy: 0.6756 - val_loss: 0.9738 - val_accuracy: 0.6636\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7878 - accuracy: 0.7266 - val_loss: 0.9111 - val_accuracy: 0.7022\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6706 - accuracy: 0.7709 - val_loss: 0.8973 - val_accuracy: 0.7005\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5653 - accuracy: 0.8030 - val_loss: 0.7734 - val_accuracy: 0.7466\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4697 - accuracy: 0.8389 - val_loss: 0.8254 - val_accuracy: 0.7446\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3780 - accuracy: 0.8691 - val_loss: 0.9590 - val_accuracy: 0.7223\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3005 - accuracy: 0.8968 - val_loss: 0.9476 - val_accuracy: 0.7390\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2393 - accuracy: 0.9158 - val_loss: 1.0936 - val_accuracy: 0.7425\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1948 - accuracy: 0.9333 - val_loss: 1.2076 - val_accuracy: 0.7319\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1605 - accuracy: 0.9452 - val_loss: 1.2041 - val_accuracy: 0.7513\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1349 - accuracy: 0.9553 - val_loss: 1.5392 - val_accuracy: 0.7315\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1173 - accuracy: 0.9611 - val_loss: 1.4595 - val_accuracy: 0.7331\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1060 - accuracy: 0.9656 - val_loss: 1.5126 - val_accuracy: 0.7404\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0980 - accuracy: 0.9675 - val_loss: 1.5977 - val_accuracy: 0.7380\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0897 - accuracy: 0.9719 - val_loss: 1.5655 - val_accuracy: 0.7392\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0863 - accuracy: 0.9731 - val_loss: 1.6031 - val_accuracy: 0.7446\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 1.6626 - val_accuracy: 0.7440\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 1.7577 - val_accuracy: 0.7437\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0706 - accuracy: 0.9786 - val_loss: 2.0984 - val_accuracy: 0.7352\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0705 - accuracy: 0.9781 - val_loss: 1.8309 - val_accuracy: 0.7397\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0673 - accuracy: 0.9791 - val_loss: 2.0030 - val_accuracy: 0.7290\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 2.0838 - val_accuracy: 0.7412\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0625 - accuracy: 0.9809 - val_loss: 2.3469 - val_accuracy: 0.7256\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0618 - accuracy: 0.9813 - val_loss: 1.9829 - val_accuracy: 0.7298\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 2.0277 - val_accuracy: 0.7271\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0587 - accuracy: 0.9825 - val_loss: 2.0611 - val_accuracy: 0.7381\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0608 - accuracy: 0.9831 - val_loss: 2.2918 - val_accuracy: 0.7243\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0548 - accuracy: 0.9846 - val_loss: 2.2400 - val_accuracy: 0.7381\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0569 - accuracy: 0.9838 - val_loss: 2.3584 - val_accuracy: 0.7332\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0573 - accuracy: 0.9836 - val_loss: 2.1877 - val_accuracy: 0.7413\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0524 - accuracy: 0.9847 - val_loss: 2.1980 - val_accuracy: 0.7371\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0520 - accuracy: 0.9854 - val_loss: 2.0158 - val_accuracy: 0.7445\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 2.2121 - val_accuracy: 0.7410\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0543 - accuracy: 0.9846 - val_loss: 2.2079 - val_accuracy: 0.7385\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0533 - accuracy: 0.9856 - val_loss: 2.4493 - val_accuracy: 0.7229\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0518 - accuracy: 0.9857 - val_loss: 2.3037 - val_accuracy: 0.7450\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0551 - accuracy: 0.9855 - val_loss: 1.9636 - val_accuracy: 0.7359\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0530 - accuracy: 0.9849 - val_loss: 2.5130 - val_accuracy: 0.7417\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0505 - accuracy: 0.9867 - val_loss: 2.1747 - val_accuracy: 0.7435\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0497 - accuracy: 0.9859 - val_loss: 2.3196 - val_accuracy: 0.7248\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0509 - accuracy: 0.9860 - val_loss: 2.5985 - val_accuracy: 0.7120\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 2.0734 - val_accuracy: 0.7359\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0496 - accuracy: 0.9866 - val_loss: 2.5882 - val_accuracy: 0.7400\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0485 - accuracy: 0.9862 - val_loss: 2.6029 - val_accuracy: 0.7423\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0513 - accuracy: 0.9865 - val_loss: 2.6817 - val_accuracy: 0.7366\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0502 - accuracy: 0.9864 - val_loss: 2.5888 - val_accuracy: 0.7415\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0561 - accuracy: 0.9851 - val_loss: 2.4887 - val_accuracy: 0.7466\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0535 - accuracy: 0.9862 - val_loss: 2.5855 - val_accuracy: 0.7406\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0573 - accuracy: 0.9847 - val_loss: 2.3155 - val_accuracy: 0.7413\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0504 - accuracy: 0.9867 - val_loss: 2.2847 - val_accuracy: 0.7422\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0548 - accuracy: 0.9853 - val_loss: 2.2634 - val_accuracy: 0.7268\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 2.6293 - val_accuracy: 0.7375\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0559 - accuracy: 0.9851 - val_loss: 2.3457 - val_accuracy: 0.7415\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0565 - accuracy: 0.9857 - val_loss: 2.1805 - val_accuracy: 0.7364\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0537 - accuracy: 0.9854 - val_loss: 2.6014 - val_accuracy: 0.7300\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0531 - accuracy: 0.9868 - val_loss: 2.1557 - val_accuracy: 0.7425\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0567 - accuracy: 0.9862 - val_loss: 2.1278 - val_accuracy: 0.7409\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0615 - accuracy: 0.9850 - val_loss: 2.2775 - val_accuracy: 0.7415\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0565 - accuracy: 0.9856 - val_loss: 2.7925 - val_accuracy: 0.7335\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0578 - accuracy: 0.9855 - val_loss: 2.1664 - val_accuracy: 0.7363\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0598 - accuracy: 0.9856 - val_loss: 2.1876 - val_accuracy: 0.7378\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0592 - accuracy: 0.9847 - val_loss: 2.6493 - val_accuracy: 0.7470\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0641 - accuracy: 0.9842 - val_loss: 2.2024 - val_accuracy: 0.7417\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0607 - accuracy: 0.9849 - val_loss: 2.3596 - val_accuracy: 0.7211\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0632 - accuracy: 0.9844 - val_loss: 2.4322 - val_accuracy: 0.7262\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0598 - accuracy: 0.9849 - val_loss: 2.9172 - val_accuracy: 0.7417\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0647 - accuracy: 0.9836 - val_loss: 2.0181 - val_accuracy: 0.7435\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0620 - accuracy: 0.9840 - val_loss: 2.9804 - val_accuracy: 0.7284\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0662 - accuracy: 0.9836 - val_loss: 2.2392 - val_accuracy: 0.7294\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0682 - accuracy: 0.9837 - val_loss: 1.8616 - val_accuracy: 0.7423\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 2.4784 - val_accuracy: 0.7273\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0696 - accuracy: 0.9819 - val_loss: 2.6889 - val_accuracy: 0.7352\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0726 - accuracy: 0.9823 - val_loss: 2.4479 - val_accuracy: 0.7421\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0681 - accuracy: 0.9829 - val_loss: 2.1071 - val_accuracy: 0.7364\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0718 - accuracy: 0.9836 - val_loss: 2.1565 - val_accuracy: 0.7214\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0796 - accuracy: 0.9811 - val_loss: 2.7804 - val_accuracy: 0.7398\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0709 - accuracy: 0.9817 - val_loss: 2.1257 - val_accuracy: 0.7415\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0682 - accuracy: 0.9820 - val_loss: 2.8119 - val_accuracy: 0.7199\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0725 - accuracy: 0.9820 - val_loss: 2.3495 - val_accuracy: 0.7409\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0680 - accuracy: 0.9827 - val_loss: 2.5118 - val_accuracy: 0.7295\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0771 - accuracy: 0.9811 - val_loss: 2.3981 - val_accuracy: 0.7385\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 1.9831 - val_accuracy: 0.7489\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0780 - accuracy: 0.9817 - val_loss: 2.5393 - val_accuracy: 0.7348\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0947 - accuracy: 0.9791 - val_loss: 2.1697 - val_accuracy: 0.7356\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0798 - accuracy: 0.9805 - val_loss: 2.7517 - val_accuracy: 0.7258\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0798 - accuracy: 0.9806 - val_loss: 2.0754 - val_accuracy: 0.7428\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0921 - accuracy: 0.9783 - val_loss: 2.6081 - val_accuracy: 0.7451\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0747 - accuracy: 0.9810 - val_loss: 1.9590 - val_accuracy: 0.7398\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0881 - accuracy: 0.9789 - val_loss: 2.5325 - val_accuracy: 0.7128\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0825 - accuracy: 0.9804 - val_loss: 1.8399 - val_accuracy: 0.7303\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0761 - accuracy: 0.9802 - val_loss: 1.8593 - val_accuracy: 0.7438\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0838 - accuracy: 0.9803 - val_loss: 1.5491 - val_accuracy: 0.7119\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0843 - accuracy: 0.9798 - val_loss: 2.8723 - val_accuracy: 0.7330\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0821 - accuracy: 0.9795 - val_loss: 2.6011 - val_accuracy: 0.7411\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0758 - accuracy: 0.9806 - val_loss: 2.3413 - val_accuracy: 0.7427\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0935 - accuracy: 0.9783 - val_loss: 1.9132 - val_accuracy: 0.7098\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.0747 - accuracy: 0.9808 - val_loss: 2.5280 - val_accuracy: 0.7067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnPQf7nrfgIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_rms.save('model_rms.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJADWD2sfmcl",
        "colab_type": "text"
      },
      "source": [
        "ADADELTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx7gSgRAfjR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dd698cd-079a-4ba4-a786-ff9b2d846a59"
      },
      "source": [
        "model_adadelta = get_model()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt2qOtzsfrHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c410e0e4-9b59-4c67-b1eb-70b539dde7be"
      },
      "source": [
        "model_adadelta.summary()\n",
        "adadelta = keras.optimizers.Adadelta()\n",
        "model_adadelta.compile(loss='sparse_categorical_crossentropy', optimizer=adadelta, metrics=['accuracy'])\n",
        "history_adadelta = model_adadelta.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 955,512\n",
            "Trainable params: 955,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.3029 - accuracy: 0.0999 - val_loss: 2.3024 - val_accuracy: 0.1002\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3020 - accuracy: 0.1016 - val_loss: 2.3015 - val_accuracy: 0.1049\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3006 - val_accuracy: 0.1236\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3002 - accuracy: 0.1295 - val_loss: 2.2997 - val_accuracy: 0.1353\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2993 - accuracy: 0.1372 - val_loss: 2.2988 - val_accuracy: 0.1362\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2983 - accuracy: 0.1406 - val_loss: 2.2978 - val_accuracy: 0.1383\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2973 - accuracy: 0.1418 - val_loss: 2.2968 - val_accuracy: 0.1391\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2962 - accuracy: 0.1411 - val_loss: 2.2956 - val_accuracy: 0.1392\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2950 - accuracy: 0.1407 - val_loss: 2.2944 - val_accuracy: 0.1353\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2936 - accuracy: 0.1385 - val_loss: 2.2929 - val_accuracy: 0.1331\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2919 - accuracy: 0.1372 - val_loss: 2.2912 - val_accuracy: 0.1325\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2901 - accuracy: 0.1387 - val_loss: 2.2893 - val_accuracy: 0.1359\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2880 - accuracy: 0.1446 - val_loss: 2.2872 - val_accuracy: 0.1421\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2858 - accuracy: 0.1504 - val_loss: 2.2851 - val_accuracy: 0.1483\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2836 - accuracy: 0.1538 - val_loss: 2.2829 - val_accuracy: 0.1497\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2813 - accuracy: 0.1564 - val_loss: 2.2806 - val_accuracy: 0.1516\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2789 - accuracy: 0.1586 - val_loss: 2.2781 - val_accuracy: 0.1537\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2762 - accuracy: 0.1614 - val_loss: 2.2753 - val_accuracy: 0.1552\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2733 - accuracy: 0.1628 - val_loss: 2.2725 - val_accuracy: 0.1554\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2705 - accuracy: 0.1629 - val_loss: 2.2698 - val_accuracy: 0.1573\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2677 - accuracy: 0.1639 - val_loss: 2.2671 - val_accuracy: 0.1586\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2650 - accuracy: 0.1647 - val_loss: 2.2643 - val_accuracy: 0.1596\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2622 - accuracy: 0.1651 - val_loss: 2.2618 - val_accuracy: 0.1616\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2596 - accuracy: 0.1657 - val_loss: 2.2592 - val_accuracy: 0.1628\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2570 - accuracy: 0.1668 - val_loss: 2.2565 - val_accuracy: 0.1629\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2532 - accuracy: 0.1676 - val_loss: 2.2477 - val_accuracy: 0.1638\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2426 - accuracy: 0.1801 - val_loss: 2.2400 - val_accuracy: 0.1832\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2360 - accuracy: 0.1944 - val_loss: 2.2344 - val_accuracy: 0.1936\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2304 - accuracy: 0.2025 - val_loss: 2.2292 - val_accuracy: 0.1995\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2254 - accuracy: 0.2055 - val_loss: 2.2243 - val_accuracy: 0.2056\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2205 - accuracy: 0.2089 - val_loss: 2.2197 - val_accuracy: 0.2079\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2158 - accuracy: 0.2100 - val_loss: 2.2150 - val_accuracy: 0.2077\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2113 - accuracy: 0.2088 - val_loss: 2.2105 - val_accuracy: 0.2085\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2068 - accuracy: 0.2074 - val_loss: 2.2062 - val_accuracy: 0.2067\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2025 - accuracy: 0.2066 - val_loss: 2.2020 - val_accuracy: 0.2039\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1983 - accuracy: 0.2050 - val_loss: 2.1979 - val_accuracy: 0.2056\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1941 - accuracy: 0.2053 - val_loss: 2.1939 - val_accuracy: 0.2044\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1900 - accuracy: 0.2048 - val_loss: 2.1897 - val_accuracy: 0.2030\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1860 - accuracy: 0.2026 - val_loss: 2.1860 - val_accuracy: 0.2044\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1819 - accuracy: 0.2031 - val_loss: 2.1818 - val_accuracy: 0.2000\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1780 - accuracy: 0.2019 - val_loss: 2.1780 - val_accuracy: 0.2009\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1742 - accuracy: 0.2021 - val_loss: 2.1744 - val_accuracy: 0.2013\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1705 - accuracy: 0.2021 - val_loss: 2.1707 - val_accuracy: 0.2031\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1669 - accuracy: 0.2031 - val_loss: 2.1672 - val_accuracy: 0.2002\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.1634 - accuracy: 0.2014 - val_loss: 2.1641 - val_accuracy: 0.2029\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1599 - accuracy: 0.2026 - val_loss: 2.1604 - val_accuracy: 0.2019\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1565 - accuracy: 0.2034 - val_loss: 2.1569 - val_accuracy: 0.2023\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1531 - accuracy: 0.2031 - val_loss: 2.1542 - val_accuracy: 0.2050\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1497 - accuracy: 0.2049 - val_loss: 2.1504 - val_accuracy: 0.2021\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1464 - accuracy: 0.2056 - val_loss: 2.1471 - val_accuracy: 0.2045\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1431 - accuracy: 0.2059 - val_loss: 2.1439 - val_accuracy: 0.2061\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1398 - accuracy: 0.2072 - val_loss: 2.1406 - val_accuracy: 0.2062\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1365 - accuracy: 0.2084 - val_loss: 2.1375 - val_accuracy: 0.2060\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1334 - accuracy: 0.2095 - val_loss: 2.1343 - val_accuracy: 0.2084\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1303 - accuracy: 0.2109 - val_loss: 2.1314 - val_accuracy: 0.2080\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1271 - accuracy: 0.2126 - val_loss: 2.1283 - val_accuracy: 0.2121\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1240 - accuracy: 0.2135 - val_loss: 2.1251 - val_accuracy: 0.2112\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1209 - accuracy: 0.2152 - val_loss: 2.1221 - val_accuracy: 0.2112\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1177 - accuracy: 0.2166 - val_loss: 2.1189 - val_accuracy: 0.2153\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1146 - accuracy: 0.2179 - val_loss: 2.1158 - val_accuracy: 0.2163\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1115 - accuracy: 0.2199 - val_loss: 2.1129 - val_accuracy: 0.2157\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1084 - accuracy: 0.2209 - val_loss: 2.1098 - val_accuracy: 0.2183\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1053 - accuracy: 0.2219 - val_loss: 2.1071 - val_accuracy: 0.2174\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1023 - accuracy: 0.2229 - val_loss: 2.1039 - val_accuracy: 0.2247\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0992 - accuracy: 0.2250 - val_loss: 2.1010 - val_accuracy: 0.2215\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0961 - accuracy: 0.2253 - val_loss: 2.0979 - val_accuracy: 0.2222\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0932 - accuracy: 0.2268 - val_loss: 2.0947 - val_accuracy: 0.2268\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0901 - accuracy: 0.2284 - val_loss: 2.0920 - val_accuracy: 0.2272\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0871 - accuracy: 0.2296 - val_loss: 2.0892 - val_accuracy: 0.2272\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0842 - accuracy: 0.2309 - val_loss: 2.0858 - val_accuracy: 0.2272\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0813 - accuracy: 0.2319 - val_loss: 2.0829 - val_accuracy: 0.2295\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0784 - accuracy: 0.2333 - val_loss: 2.0801 - val_accuracy: 0.2324\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0755 - accuracy: 0.2340 - val_loss: 2.0772 - val_accuracy: 0.2338\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0727 - accuracy: 0.2351 - val_loss: 2.0745 - val_accuracy: 0.2363\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0699 - accuracy: 0.2366 - val_loss: 2.0716 - val_accuracy: 0.2360\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0670 - accuracy: 0.2372 - val_loss: 2.0688 - val_accuracy: 0.2387\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0642 - accuracy: 0.2384 - val_loss: 2.0657 - val_accuracy: 0.2349\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0614 - accuracy: 0.2386 - val_loss: 2.0628 - val_accuracy: 0.2367\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0586 - accuracy: 0.2398 - val_loss: 2.0600 - val_accuracy: 0.2384\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0559 - accuracy: 0.2411 - val_loss: 2.0573 - val_accuracy: 0.2407\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0531 - accuracy: 0.2418 - val_loss: 2.0546 - val_accuracy: 0.2407\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0503 - accuracy: 0.2431 - val_loss: 2.0518 - val_accuracy: 0.2392\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0477 - accuracy: 0.2434 - val_loss: 2.0495 - val_accuracy: 0.2443\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0450 - accuracy: 0.2450 - val_loss: 2.0463 - val_accuracy: 0.2433\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0421 - accuracy: 0.2455 - val_loss: 2.0435 - val_accuracy: 0.2447\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0395 - accuracy: 0.2465 - val_loss: 2.0404 - val_accuracy: 0.2431\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0367 - accuracy: 0.2465 - val_loss: 2.0380 - val_accuracy: 0.2459\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0341 - accuracy: 0.2477 - val_loss: 2.0351 - val_accuracy: 0.2463\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0314 - accuracy: 0.2498 - val_loss: 2.0328 - val_accuracy: 0.2490\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0288 - accuracy: 0.2496 - val_loss: 2.0299 - val_accuracy: 0.2463\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0262 - accuracy: 0.2504 - val_loss: 2.0269 - val_accuracy: 0.2480\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0235 - accuracy: 0.2517 - val_loss: 2.0248 - val_accuracy: 0.2499\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0209 - accuracy: 0.2525 - val_loss: 2.0218 - val_accuracy: 0.2505\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0183 - accuracy: 0.2531 - val_loss: 2.0192 - val_accuracy: 0.2512\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0157 - accuracy: 0.2534 - val_loss: 2.0167 - val_accuracy: 0.2535\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0131 - accuracy: 0.2546 - val_loss: 2.0137 - val_accuracy: 0.2523\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0105 - accuracy: 0.2554 - val_loss: 2.0110 - val_accuracy: 0.2533\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0079 - accuracy: 0.2560 - val_loss: 2.0086 - val_accuracy: 0.2529\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0054 - accuracy: 0.2563 - val_loss: 2.0058 - val_accuracy: 0.2544\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0028 - accuracy: 0.2573 - val_loss: 2.0032 - val_accuracy: 0.2548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V16_uP1ftxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adadelta.save('model_adadelta.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d46yOgUzhUT2",
        "colab_type": "text"
      },
      "source": [
        "Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhRnA0g_hTx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8c7b563-0cfc-4ba3-ad55-47198f777aff"
      },
      "source": [
        "model_adagrad = get_model()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7UN7MXhaLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6677d27-7781-4e60-e6c0-df28b0686aa1"
      },
      "source": [
        "model_adagrad.summary()\n",
        "adagrad = keras.optimizers.Adagrad()\n",
        "model_adagrad.compile(loss='sparse_categorical_crossentropy', optimizer=adagrad, metrics=['accuracy'])\n",
        "history_adagrad= model_adagrad.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 955,512\n",
            "Trainable params: 955,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3009 - accuracy: 0.1221 - val_loss: 2.2970 - val_accuracy: 0.1324\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2922 - accuracy: 0.1353 - val_loss: 2.2871 - val_accuracy: 0.1416\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2773 - accuracy: 0.1543 - val_loss: 2.2674 - val_accuracy: 0.1706\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2523 - accuracy: 0.1663 - val_loss: 2.2384 - val_accuracy: 0.1759\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2217 - accuracy: 0.1752 - val_loss: 2.2067 - val_accuracy: 0.1811\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1873 - accuracy: 0.1964 - val_loss: 2.1682 - val_accuracy: 0.2187\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1451 - accuracy: 0.2212 - val_loss: 2.1223 - val_accuracy: 0.2407\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1002 - accuracy: 0.2399 - val_loss: 2.0843 - val_accuracy: 0.2328\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0459 - accuracy: 0.2578 - val_loss: 2.0150 - val_accuracy: 0.2683\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9885 - accuracy: 0.2737 - val_loss: 1.9544 - val_accuracy: 0.2901\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9364 - accuracy: 0.2915 - val_loss: 1.9035 - val_accuracy: 0.3107\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8966 - accuracy: 0.3069 - val_loss: 1.9326 - val_accuracy: 0.2947\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8617 - accuracy: 0.3207 - val_loss: 1.8962 - val_accuracy: 0.3053\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8313 - accuracy: 0.3306 - val_loss: 1.8234 - val_accuracy: 0.3417\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8068 - accuracy: 0.3433 - val_loss: 1.7953 - val_accuracy: 0.3532\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7845 - accuracy: 0.3531 - val_loss: 1.9308 - val_accuracy: 0.3048\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7652 - accuracy: 0.3593 - val_loss: 1.7902 - val_accuracy: 0.3452\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7453 - accuracy: 0.3670 - val_loss: 1.7452 - val_accuracy: 0.3666\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7311 - accuracy: 0.3741 - val_loss: 1.7656 - val_accuracy: 0.3697\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7158 - accuracy: 0.3779 - val_loss: 1.7244 - val_accuracy: 0.3750\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7002 - accuracy: 0.3853 - val_loss: 1.7033 - val_accuracy: 0.3837\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6856 - accuracy: 0.3911 - val_loss: 1.6935 - val_accuracy: 0.3854\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6759 - accuracy: 0.3953 - val_loss: 1.6763 - val_accuracy: 0.3967\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6622 - accuracy: 0.4009 - val_loss: 1.6600 - val_accuracy: 0.3984\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6532 - accuracy: 0.4030 - val_loss: 1.6739 - val_accuracy: 0.3889\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6422 - accuracy: 0.4080 - val_loss: 1.6410 - val_accuracy: 0.4121\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6330 - accuracy: 0.4109 - val_loss: 1.6436 - val_accuracy: 0.4026\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6243 - accuracy: 0.4157 - val_loss: 1.6351 - val_accuracy: 0.4106\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6135 - accuracy: 0.4184 - val_loss: 1.6384 - val_accuracy: 0.4029\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6065 - accuracy: 0.4218 - val_loss: 1.6217 - val_accuracy: 0.4162\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5991 - accuracy: 0.4244 - val_loss: 1.6107 - val_accuracy: 0.4191\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5898 - accuracy: 0.4292 - val_loss: 1.6124 - val_accuracy: 0.4173\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5835 - accuracy: 0.4294 - val_loss: 1.6124 - val_accuracy: 0.4218\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5780 - accuracy: 0.4336 - val_loss: 1.5990 - val_accuracy: 0.4266\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5681 - accuracy: 0.4376 - val_loss: 1.5804 - val_accuracy: 0.4342\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5635 - accuracy: 0.4381 - val_loss: 1.5698 - val_accuracy: 0.4371\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5570 - accuracy: 0.4382 - val_loss: 1.5688 - val_accuracy: 0.4348\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5497 - accuracy: 0.4443 - val_loss: 1.5763 - val_accuracy: 0.4311\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5436 - accuracy: 0.4470 - val_loss: 1.5579 - val_accuracy: 0.4456\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5372 - accuracy: 0.4473 - val_loss: 1.5531 - val_accuracy: 0.4373\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5313 - accuracy: 0.4498 - val_loss: 1.5707 - val_accuracy: 0.4293\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5264 - accuracy: 0.4522 - val_loss: 1.5346 - val_accuracy: 0.4489\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5194 - accuracy: 0.4545 - val_loss: 1.5353 - val_accuracy: 0.4468\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5152 - accuracy: 0.4559 - val_loss: 1.5377 - val_accuracy: 0.4455\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5090 - accuracy: 0.4593 - val_loss: 1.5213 - val_accuracy: 0.4540\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5042 - accuracy: 0.4602 - val_loss: 1.5221 - val_accuracy: 0.4522\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4988 - accuracy: 0.4624 - val_loss: 1.5168 - val_accuracy: 0.4505\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4929 - accuracy: 0.4642 - val_loss: 1.5412 - val_accuracy: 0.4511\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4881 - accuracy: 0.4657 - val_loss: 1.5054 - val_accuracy: 0.4593\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4826 - accuracy: 0.4672 - val_loss: 1.5063 - val_accuracy: 0.4583\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4782 - accuracy: 0.4701 - val_loss: 1.4986 - val_accuracy: 0.4613\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4731 - accuracy: 0.4712 - val_loss: 1.4935 - val_accuracy: 0.4632\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4683 - accuracy: 0.4737 - val_loss: 1.4981 - val_accuracy: 0.4639\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4639 - accuracy: 0.4756 - val_loss: 1.4870 - val_accuracy: 0.4661\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4600 - accuracy: 0.4775 - val_loss: 1.4818 - val_accuracy: 0.4656\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4557 - accuracy: 0.4795 - val_loss: 1.4919 - val_accuracy: 0.4627\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4503 - accuracy: 0.4796 - val_loss: 1.4822 - val_accuracy: 0.4691\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4468 - accuracy: 0.4839 - val_loss: 1.4877 - val_accuracy: 0.4606\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4412 - accuracy: 0.4853 - val_loss: 1.4697 - val_accuracy: 0.4717\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4380 - accuracy: 0.4859 - val_loss: 1.4740 - val_accuracy: 0.4711\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4328 - accuracy: 0.4887 - val_loss: 1.4636 - val_accuracy: 0.4752\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4289 - accuracy: 0.4909 - val_loss: 1.4651 - val_accuracy: 0.4779\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4243 - accuracy: 0.4924 - val_loss: 1.4503 - val_accuracy: 0.4799\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4196 - accuracy: 0.4943 - val_loss: 1.4729 - val_accuracy: 0.4712\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4154 - accuracy: 0.4957 - val_loss: 1.4471 - val_accuracy: 0.4826\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4110 - accuracy: 0.4979 - val_loss: 1.4772 - val_accuracy: 0.4729\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4081 - accuracy: 0.4987 - val_loss: 1.4392 - val_accuracy: 0.4835\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4028 - accuracy: 0.5009 - val_loss: 1.4341 - val_accuracy: 0.4890\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3996 - accuracy: 0.5008 - val_loss: 1.4318 - val_accuracy: 0.4872\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3957 - accuracy: 0.5035 - val_loss: 1.4562 - val_accuracy: 0.4821\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3918 - accuracy: 0.5044 - val_loss: 1.4265 - val_accuracy: 0.4882\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3875 - accuracy: 0.5067 - val_loss: 1.4221 - val_accuracy: 0.4888\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3833 - accuracy: 0.5082 - val_loss: 1.4296 - val_accuracy: 0.4915\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3790 - accuracy: 0.5103 - val_loss: 1.4266 - val_accuracy: 0.4875\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3761 - accuracy: 0.5124 - val_loss: 1.4098 - val_accuracy: 0.4987\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3721 - accuracy: 0.5128 - val_loss: 1.4138 - val_accuracy: 0.4968\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3693 - accuracy: 0.5126 - val_loss: 1.4010 - val_accuracy: 0.5037\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3640 - accuracy: 0.5165 - val_loss: 1.4022 - val_accuracy: 0.5001\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3622 - accuracy: 0.5161 - val_loss: 1.4002 - val_accuracy: 0.5019\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3583 - accuracy: 0.5184 - val_loss: 1.3956 - val_accuracy: 0.5061\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3553 - accuracy: 0.5214 - val_loss: 1.4686 - val_accuracy: 0.4891\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3491 - accuracy: 0.5215 - val_loss: 1.3867 - val_accuracy: 0.5095\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3472 - accuracy: 0.5236 - val_loss: 1.3951 - val_accuracy: 0.5026\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3442 - accuracy: 0.5246 - val_loss: 1.4123 - val_accuracy: 0.4964\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3402 - accuracy: 0.5262 - val_loss: 1.4192 - val_accuracy: 0.4923\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3381 - accuracy: 0.5266 - val_loss: 1.3811 - val_accuracy: 0.5082\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3332 - accuracy: 0.5289 - val_loss: 1.3834 - val_accuracy: 0.5050\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3307 - accuracy: 0.5305 - val_loss: 1.3748 - val_accuracy: 0.5140\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3269 - accuracy: 0.5321 - val_loss: 1.3741 - val_accuracy: 0.5086\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3243 - accuracy: 0.5322 - val_loss: 1.3861 - val_accuracy: 0.5116\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3196 - accuracy: 0.5329 - val_loss: 1.3763 - val_accuracy: 0.5077\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3173 - accuracy: 0.5356 - val_loss: 1.3663 - val_accuracy: 0.5164\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3142 - accuracy: 0.5357 - val_loss: 1.3595 - val_accuracy: 0.5183\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3118 - accuracy: 0.5382 - val_loss: 1.3745 - val_accuracy: 0.5137\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3079 - accuracy: 0.5400 - val_loss: 1.3609 - val_accuracy: 0.5195\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3050 - accuracy: 0.5402 - val_loss: 1.3579 - val_accuracy: 0.5197\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3019 - accuracy: 0.5410 - val_loss: 1.3606 - val_accuracy: 0.5150\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2995 - accuracy: 0.5427 - val_loss: 1.3540 - val_accuracy: 0.5159\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2950 - accuracy: 0.5445 - val_loss: 1.3522 - val_accuracy: 0.5209\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2921 - accuracy: 0.5457 - val_loss: 1.3516 - val_accuracy: 0.5214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym_IGjC0hf12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adagrad.save('model_adagrad.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sHhbhinhhpp",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy** **Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NPGjWuFhhBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "d9a1805f-5c73-4852-c113-2ae1b4a1fe9a"
      },
      "source": [
        "# Combined Training Accuracy Plot\n",
        "\n",
        "plt.plot(history_sgd_plain.history['accuracy'])\n",
        "plt.plot(history_adam.history['accuracy'])\n",
        "plt.plot(history_rmsprop.history['accuracy'])\n",
        "plt.plot(history_adadelta.history['accuracy'])\n",
        "plt.plot(history_adagrad.history['accuracy'])\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad'])\n",
        "plt.savefig('Combined-Accuracy.jpg', dpi=200)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BPOUhO7BZNo",
        "colab_type": "text"
      },
      "source": [
        "Different Architecture\n",
        "1. adding more hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRMrISF3BmcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_new_model_architecture():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=input_shape, activation='relu'))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(units=512, activation='relu'))\n",
        "    model.add(Dense(units=512, activation='relu'))\n",
        "    model.add(Dense(units=512, activation='relu'))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=32, activation='relu'))\n",
        "    model.add(Dense(units=10, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "    \n",
        "    print('Model initialized. Please compile before training.')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4TzPOTjB8fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFjByeXlCf3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22c31f84-154f-42b5-c67d-58c915be2f30"
      },
      "source": [
        "model_sgd_plain_2 = get_new_model_architecture()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kUEWwdaCg6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fef5bc3-a0c7-4d5b-b748-9da7195f164c"
      },
      "source": [
        "model_sgd_plain_2.summary()\n",
        "sgd_plain = keras.optimizers.SGD()\n",
        "model_sgd_plain_2.compile(loss='sparse_categorical_crossentropy', optimizer=sgd_plain, metrics=['accuracy'])\n",
        "history_sgd_plain_2 = model_sgd_plain_2.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 1,480,824\n",
            "Trainable params: 1,480,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3018 - accuracy: 0.1080 - val_loss: 2.3004 - val_accuracy: 0.1022\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2977 - accuracy: 0.1455 - val_loss: 2.2928 - val_accuracy: 0.1799\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2834 - accuracy: 0.1837 - val_loss: 2.2659 - val_accuracy: 0.1804\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2239 - accuracy: 0.1928 - val_loss: 2.2593 - val_accuracy: 0.1583\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1037 - accuracy: 0.2383 - val_loss: 2.0783 - val_accuracy: 0.2212\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.9831 - accuracy: 0.2879 - val_loss: 1.9771 - val_accuracy: 0.3021\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8893 - accuracy: 0.3276 - val_loss: 1.8651 - val_accuracy: 0.3353\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8032 - accuracy: 0.3591 - val_loss: 1.7287 - val_accuracy: 0.3831\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.7360 - accuracy: 0.3824 - val_loss: 1.6931 - val_accuracy: 0.4006\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6695 - accuracy: 0.4057 - val_loss: 1.6688 - val_accuracy: 0.3996\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5976 - accuracy: 0.4265 - val_loss: 1.5485 - val_accuracy: 0.4391\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5396 - accuracy: 0.4466 - val_loss: 1.5564 - val_accuracy: 0.4379\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4909 - accuracy: 0.4669 - val_loss: 1.4692 - val_accuracy: 0.4798\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4432 - accuracy: 0.4789 - val_loss: 1.5193 - val_accuracy: 0.4507\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4004 - accuracy: 0.4970 - val_loss: 1.4029 - val_accuracy: 0.4944\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3626 - accuracy: 0.5064 - val_loss: 1.3696 - val_accuracy: 0.5116\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3286 - accuracy: 0.5224 - val_loss: 1.3598 - val_accuracy: 0.5068\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2936 - accuracy: 0.5367 - val_loss: 1.3309 - val_accuracy: 0.5252\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2582 - accuracy: 0.5502 - val_loss: 1.3471 - val_accuracy: 0.5216\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2242 - accuracy: 0.5614 - val_loss: 1.3580 - val_accuracy: 0.5216\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.1914 - accuracy: 0.5751 - val_loss: 1.3132 - val_accuracy: 0.5354\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.1592 - accuracy: 0.5869 - val_loss: 1.2782 - val_accuracy: 0.5475\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.1236 - accuracy: 0.5992 - val_loss: 1.3332 - val_accuracy: 0.5387\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0879 - accuracy: 0.6121 - val_loss: 1.2624 - val_accuracy: 0.5606\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0569 - accuracy: 0.6220 - val_loss: 1.2742 - val_accuracy: 0.5571\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0217 - accuracy: 0.6350 - val_loss: 1.3385 - val_accuracy: 0.5418\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9918 - accuracy: 0.6456 - val_loss: 1.2566 - val_accuracy: 0.5645\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9557 - accuracy: 0.6578 - val_loss: 1.2207 - val_accuracy: 0.5817\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9242 - accuracy: 0.6729 - val_loss: 1.2547 - val_accuracy: 0.5737\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8898 - accuracy: 0.6819 - val_loss: 1.2591 - val_accuracy: 0.5790\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8523 - accuracy: 0.6944 - val_loss: 1.2414 - val_accuracy: 0.5795\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8088 - accuracy: 0.7129 - val_loss: 1.3136 - val_accuracy: 0.5766\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7811 - accuracy: 0.7197 - val_loss: 1.2738 - val_accuracy: 0.5836\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7405 - accuracy: 0.7377 - val_loss: 1.5496 - val_accuracy: 0.5305\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7111 - accuracy: 0.7470 - val_loss: 1.3562 - val_accuracy: 0.5805\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6721 - accuracy: 0.7619 - val_loss: 1.4892 - val_accuracy: 0.5619\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.6218 - accuracy: 0.7765 - val_loss: 1.3713 - val_accuracy: 0.5901\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5799 - accuracy: 0.7936 - val_loss: 1.4823 - val_accuracy: 0.5767\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5579 - accuracy: 0.8009 - val_loss: 1.4675 - val_accuracy: 0.5882\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5155 - accuracy: 0.8149 - val_loss: 1.4916 - val_accuracy: 0.5865\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4808 - accuracy: 0.8321 - val_loss: 1.5686 - val_accuracy: 0.5831\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4588 - accuracy: 0.8382 - val_loss: 1.8009 - val_accuracy: 0.5586\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4014 - accuracy: 0.8584 - val_loss: 1.7489 - val_accuracy: 0.5687\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3666 - accuracy: 0.8735 - val_loss: 1.7705 - val_accuracy: 0.5864\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3485 - accuracy: 0.8829 - val_loss: 1.9191 - val_accuracy: 0.5763\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3124 - accuracy: 0.8936 - val_loss: 1.9925 - val_accuracy: 0.5820\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2896 - accuracy: 0.9038 - val_loss: 2.1844 - val_accuracy: 0.5305\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2735 - accuracy: 0.9104 - val_loss: 1.9530 - val_accuracy: 0.5891\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2097 - accuracy: 0.9334 - val_loss: 2.1448 - val_accuracy: 0.5836\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2257 - accuracy: 0.9287 - val_loss: 2.1385 - val_accuracy: 0.5879\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2044 - accuracy: 0.9384 - val_loss: 1.9318 - val_accuracy: 0.5675\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.2528 - accuracy: 0.9301 - val_loss: 1.9893 - val_accuracy: 0.5935\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1201 - accuracy: 0.9657 - val_loss: 2.3126 - val_accuracy: 0.5874\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1272 - accuracy: 0.9652 - val_loss: 2.0183 - val_accuracy: 0.5799\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1218 - accuracy: 0.9706 - val_loss: 2.0632 - val_accuracy: 0.5750\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0969 - accuracy: 0.9758 - val_loss: 2.6802 - val_accuracy: 0.5871\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0245 - accuracy: 0.9955 - val_loss: 3.0764 - val_accuracy: 0.5938\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 3.3271 - val_accuracy: 0.6015\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 3.6065 - val_accuracy: 0.5959\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 3.7222 - val_accuracy: 0.5972\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 3.8196 - val_accuracy: 0.5965\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 3.9541 - val_accuracy: 0.5989\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 4.0448 - val_accuracy: 0.5996\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 4.1311 - val_accuracy: 0.5987\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 4.1762 - val_accuracy: 0.5983\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 9.7215e-04 - accuracy: 0.9999 - val_loss: 4.2462 - val_accuracy: 0.5990\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 8.4959e-04 - accuracy: 0.9999 - val_loss: 4.3034 - val_accuracy: 0.6000\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 7.5830e-04 - accuracy: 0.9999 - val_loss: 4.3580 - val_accuracy: 0.5982\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 7.1205e-04 - accuracy: 1.0000 - val_loss: 4.4102 - val_accuracy: 0.5991\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 6.5808e-04 - accuracy: 1.0000 - val_loss: 4.4430 - val_accuracy: 0.5981\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 6.6121e-04 - accuracy: 1.0000 - val_loss: 4.4915 - val_accuracy: 0.5983\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.8453e-04 - accuracy: 1.0000 - val_loss: 4.5116 - val_accuracy: 0.5980\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.8090e-04 - accuracy: 1.0000 - val_loss: 4.5531 - val_accuracy: 0.5973\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.0323e-04 - accuracy: 1.0000 - val_loss: 4.5953 - val_accuracy: 0.5975\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.7628e-04 - accuracy: 1.0000 - val_loss: 4.6349 - val_accuracy: 0.5970\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 5.0643e-04 - accuracy: 1.0000 - val_loss: 4.6549 - val_accuracy: 0.5973\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 4.7995e-04 - accuracy: 1.0000 - val_loss: 4.6878 - val_accuracy: 0.5969\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 4.1203e-04 - accuracy: 1.0000 - val_loss: 4.7215 - val_accuracy: 0.5969\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 3.9363e-04 - accuracy: 1.0000 - val_loss: 4.7474 - val_accuracy: 0.5975\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 3.7779e-04 - accuracy: 1.0000 - val_loss: 4.7785 - val_accuracy: 0.5969\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 3.8516e-04 - accuracy: 1.0000 - val_loss: 4.7958 - val_accuracy: 0.5966\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.5114e-04 - accuracy: 1.0000 - val_loss: 4.8211 - val_accuracy: 0.5979\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.2700e-04 - accuracy: 1.0000 - val_loss: 4.8434 - val_accuracy: 0.5963\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.1499e-04 - accuracy: 1.0000 - val_loss: 4.8699 - val_accuracy: 0.5974\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.0055e-04 - accuracy: 1.0000 - val_loss: 4.8856 - val_accuracy: 0.5976\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.1878e-04 - accuracy: 1.0000 - val_loss: 4.9166 - val_accuracy: 0.5978\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.9577e-04 - accuracy: 1.0000 - val_loss: 4.9346 - val_accuracy: 0.5969\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.7500e-04 - accuracy: 1.0000 - val_loss: 4.9559 - val_accuracy: 0.5979\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.6413e-04 - accuracy: 1.0000 - val_loss: 4.9704 - val_accuracy: 0.5950\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.5438e-04 - accuracy: 1.0000 - val_loss: 4.9917 - val_accuracy: 0.5964\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.4335e-04 - accuracy: 1.0000 - val_loss: 5.0103 - val_accuracy: 0.5968\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3807e-04 - accuracy: 1.0000 - val_loss: 5.0229 - val_accuracy: 0.5960\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.3892e-04 - accuracy: 1.0000 - val_loss: 5.0438 - val_accuracy: 0.5967\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.5476e-04 - accuracy: 1.0000 - val_loss: 5.0616 - val_accuracy: 0.5973\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 3.3465e-04 - accuracy: 1.0000 - val_loss: 5.0596 - val_accuracy: 0.5935\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 5.0723 - val_accuracy: 0.5934\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.7691e-04 - accuracy: 1.0000 - val_loss: 5.1005 - val_accuracy: 0.5959\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2341e-04 - accuracy: 1.0000 - val_loss: 5.1143 - val_accuracy: 0.5957\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2268e-04 - accuracy: 1.0000 - val_loss: 5.1310 - val_accuracy: 0.5960\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.0875e-04 - accuracy: 1.0000 - val_loss: 5.1426 - val_accuracy: 0.5964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vantuu3ZCl8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_sgd_plain_2.save('model_sgd_plain_2.h5')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu8zEHi9CwJF",
        "colab_type": "text"
      },
      "source": [
        "ADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t5Q08dJDCrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc1f0931-3b1c-4a3a-a6cf-dbbc5f56ec69"
      },
      "source": [
        "model_adam_2 = get_new_model_architecture()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLeqpd2HCvhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1abbdad0-ace1-4e64-df5b-2ddc23760717"
      },
      "source": [
        "model_adam_2.summary()\n",
        "adam = keras.optimizers.Adam()\n",
        "model_adam_2.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "history_adam_2 = model_adam_2.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 1,480,824\n",
            "Trainable params: 1,480,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7577 - accuracy: 0.3274 - val_loss: 1.4439 - val_accuracy: 0.4706\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2423 - accuracy: 0.5507 - val_loss: 1.1161 - val_accuracy: 0.6084\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.0024 - accuracy: 0.6474 - val_loss: 0.9705 - val_accuracy: 0.6593\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.8309 - accuracy: 0.7088 - val_loss: 0.8745 - val_accuracy: 0.6965\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7042 - accuracy: 0.7549 - val_loss: 0.8190 - val_accuracy: 0.7173\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5889 - accuracy: 0.7936 - val_loss: 0.8653 - val_accuracy: 0.7180\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4874 - accuracy: 0.8308 - val_loss: 0.8519 - val_accuracy: 0.7336\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4031 - accuracy: 0.8599 - val_loss: 0.8999 - val_accuracy: 0.7240\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3190 - accuracy: 0.8893 - val_loss: 0.9800 - val_accuracy: 0.7284\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2582 - accuracy: 0.9130 - val_loss: 1.0332 - val_accuracy: 0.7325\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2167 - accuracy: 0.9250 - val_loss: 1.1405 - val_accuracy: 0.7158\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1782 - accuracy: 0.9382 - val_loss: 1.2419 - val_accuracy: 0.7186\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1464 - accuracy: 0.9505 - val_loss: 1.2595 - val_accuracy: 0.7269\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1348 - accuracy: 0.9554 - val_loss: 1.2471 - val_accuracy: 0.7322\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.1098 - accuracy: 0.9629 - val_loss: 1.3944 - val_accuracy: 0.7244\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1052 - accuracy: 0.9653 - val_loss: 1.3914 - val_accuracy: 0.7257\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0951 - accuracy: 0.9689 - val_loss: 1.3387 - val_accuracy: 0.7274\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0857 - accuracy: 0.9722 - val_loss: 1.4944 - val_accuracy: 0.7250\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0862 - accuracy: 0.9722 - val_loss: 1.3030 - val_accuracy: 0.7187\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0721 - accuracy: 0.9757 - val_loss: 1.5665 - val_accuracy: 0.7166\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0788 - accuracy: 0.9737 - val_loss: 1.4811 - val_accuracy: 0.7328\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: 1.6513 - val_accuracy: 0.7371\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0669 - accuracy: 0.9785 - val_loss: 1.5177 - val_accuracy: 0.7274\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 1.6186 - val_accuracy: 0.7312\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 1.7223 - val_accuracy: 0.7179\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 1.5639 - val_accuracy: 0.7219\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 1.5867 - val_accuracy: 0.7264\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0578 - accuracy: 0.9817 - val_loss: 1.5695 - val_accuracy: 0.7306\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 1.6111 - val_accuracy: 0.7279\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0523 - accuracy: 0.9828 - val_loss: 1.5562 - val_accuracy: 0.7313\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 1.6496 - val_accuracy: 0.7209\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0458 - accuracy: 0.9852 - val_loss: 1.7570 - val_accuracy: 0.7220\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 1.5343 - val_accuracy: 0.7230\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 1.6652 - val_accuracy: 0.7321\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 1.7993 - val_accuracy: 0.7145\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 1.7838 - val_accuracy: 0.7176\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 1.6766 - val_accuracy: 0.7211\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 1.6924 - val_accuracy: 0.7223\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 1.7630 - val_accuracy: 0.7307\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 1.7717 - val_accuracy: 0.7295\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 1.7950 - val_accuracy: 0.7315\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 1.8076 - val_accuracy: 0.7211\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 1.7832 - val_accuracy: 0.7229\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0439 - accuracy: 0.9869 - val_loss: 1.7572 - val_accuracy: 0.7212\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 1.7021 - val_accuracy: 0.7141\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 1.8606 - val_accuracy: 0.7306\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 1.8474 - val_accuracy: 0.7172\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 1.7770 - val_accuracy: 0.7312\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 1.7027 - val_accuracy: 0.7372\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 1.7196 - val_accuracy: 0.7332\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 1.7770 - val_accuracy: 0.7267\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 2.0552 - val_accuracy: 0.7263\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0333 - accuracy: 0.9904 - val_loss: 1.9563 - val_accuracy: 0.7134\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 1.9061 - val_accuracy: 0.7297\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 1.7978 - val_accuracy: 0.7291\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 2.0236 - val_accuracy: 0.7256\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 1.7558 - val_accuracy: 0.7275\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 1.8500 - val_accuracy: 0.7163\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0336 - accuracy: 0.9898 - val_loss: 1.9195 - val_accuracy: 0.7353\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 1.8407 - val_accuracy: 0.7269\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0280 - accuracy: 0.9921 - val_loss: 1.7978 - val_accuracy: 0.7276\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 1.8329 - val_accuracy: 0.7281\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 1.9208 - val_accuracy: 0.7338\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 2.1225 - val_accuracy: 0.7239\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 2.0123 - val_accuracy: 0.7211\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 1.9231 - val_accuracy: 0.7296\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 1.8728 - val_accuracy: 0.7295\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 2.0695 - val_accuracy: 0.7323\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 1.8729 - val_accuracy: 0.7302\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 2.0271 - val_accuracy: 0.7247\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 2.1929 - val_accuracy: 0.7306\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 2.0834 - val_accuracy: 0.7270\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 1.9306 - val_accuracy: 0.7317\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 1.9877 - val_accuracy: 0.7361\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 2.1153 - val_accuracy: 0.7267\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0331 - accuracy: 0.9916 - val_loss: 2.1059 - val_accuracy: 0.7261\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 1.7963 - val_accuracy: 0.7292\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 2.1532 - val_accuracy: 0.7344\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 1.9646 - val_accuracy: 0.7275\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 2.1434 - val_accuracy: 0.7335\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 2.1276 - val_accuracy: 0.7351\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 2.0711 - val_accuracy: 0.7338\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 1.9876 - val_accuracy: 0.7411\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 1.9103 - val_accuracy: 0.7305\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 2.0962 - val_accuracy: 0.7291\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 1.7316 - val_accuracy: 0.7287\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 1.8969 - val_accuracy: 0.7233\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 2.0378 - val_accuracy: 0.7346\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 1.9714 - val_accuracy: 0.7282\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 2.0644 - val_accuracy: 0.7339\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0245 - accuracy: 0.9935 - val_loss: 1.8761 - val_accuracy: 0.7351\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 1.9085 - val_accuracy: 0.7318\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 1.9770 - val_accuracy: 0.7321\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 2.1353 - val_accuracy: 0.7284\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 1.9678 - val_accuracy: 0.7304\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 2.0617 - val_accuracy: 0.7279\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 2.1073 - val_accuracy: 0.7222\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 2.2513 - val_accuracy: 0.7257\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 2.0534 - val_accuracy: 0.7261\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 2.2579 - val_accuracy: 0.7338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUjmN_8TDJVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adam_2.save('model_adam_2.h5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3a5KJflDN4D",
        "colab_type": "text"
      },
      "source": [
        "RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKCQpQhUDc9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b74fb2c4-6b3c-4bad-ebac-f5fc78a2358b"
      },
      "source": [
        "model_rms_2 = get_new_model_architecture()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx68OSa1DhHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4df3b45-cd2d-45c4-c7fe-c6fc9933025d"
      },
      "source": [
        "model_rms_2.summary()\n",
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model_rms_2.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "history_rmsprop_2 = model_rms_2.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 1,480,824\n",
            "Trainable params: 1,480,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.0899 - accuracy: 0.2326 - val_loss: 1.7060 - val_accuracy: 0.3960\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5546 - accuracy: 0.4466 - val_loss: 1.4631 - val_accuracy: 0.4736\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2721 - accuracy: 0.5581 - val_loss: 1.1306 - val_accuracy: 0.6057\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0683 - accuracy: 0.6347 - val_loss: 1.1489 - val_accuracy: 0.6114\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9079 - accuracy: 0.6907 - val_loss: 0.9954 - val_accuracy: 0.6673\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7704 - accuracy: 0.7400 - val_loss: 0.9504 - val_accuracy: 0.6864\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6579 - accuracy: 0.7779 - val_loss: 0.9410 - val_accuracy: 0.7141\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5487 - accuracy: 0.8141 - val_loss: 0.9840 - val_accuracy: 0.6987\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4598 - accuracy: 0.8458 - val_loss: 1.0682 - val_accuracy: 0.7262\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3892 - accuracy: 0.8710 - val_loss: 1.0008 - val_accuracy: 0.7259\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3217 - accuracy: 0.8934 - val_loss: 1.0763 - val_accuracy: 0.7309\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2713 - accuracy: 0.9106 - val_loss: 1.1439 - val_accuracy: 0.7266\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2347 - accuracy: 0.9249 - val_loss: 1.1452 - val_accuracy: 0.7449\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2043 - accuracy: 0.9349 - val_loss: 1.3165 - val_accuracy: 0.7374\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1849 - accuracy: 0.9437 - val_loss: 1.3095 - val_accuracy: 0.7067\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1697 - accuracy: 0.9473 - val_loss: 1.6275 - val_accuracy: 0.6921\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1545 - accuracy: 0.9525 - val_loss: 1.5332 - val_accuracy: 0.7297\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1493 - accuracy: 0.9551 - val_loss: 1.9624 - val_accuracy: 0.7123\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1358 - accuracy: 0.9603 - val_loss: 1.7118 - val_accuracy: 0.7293\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1318 - accuracy: 0.9627 - val_loss: 1.4547 - val_accuracy: 0.7226\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1252 - accuracy: 0.9634 - val_loss: 1.4501 - val_accuracy: 0.7362\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1277 - accuracy: 0.9643 - val_loss: 1.7950 - val_accuracy: 0.7180\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1264 - accuracy: 0.9649 - val_loss: 1.5230 - val_accuracy: 0.7318\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1232 - accuracy: 0.9652 - val_loss: 1.6792 - val_accuracy: 0.7241\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1188 - accuracy: 0.9664 - val_loss: 1.7790 - val_accuracy: 0.7089\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1272 - accuracy: 0.9650 - val_loss: 1.4051 - val_accuracy: 0.7304\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1224 - accuracy: 0.9659 - val_loss: 1.3508 - val_accuracy: 0.7323\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1326 - accuracy: 0.9665 - val_loss: 2.4126 - val_accuracy: 0.7299\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1171 - accuracy: 0.9682 - val_loss: 2.0393 - val_accuracy: 0.7226\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1290 - accuracy: 0.9662 - val_loss: 2.2069 - val_accuracy: 0.7287\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1172 - accuracy: 0.9692 - val_loss: 1.8337 - val_accuracy: 0.7384\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1376 - accuracy: 0.9664 - val_loss: 1.8335 - val_accuracy: 0.7386\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1214 - accuracy: 0.9686 - val_loss: 2.0799 - val_accuracy: 0.7191\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1208 - accuracy: 0.9687 - val_loss: 2.6104 - val_accuracy: 0.7301\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1259 - accuracy: 0.9661 - val_loss: 2.3798 - val_accuracy: 0.7434\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1267 - accuracy: 0.9663 - val_loss: 1.8269 - val_accuracy: 0.7394\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1313 - accuracy: 0.9662 - val_loss: 2.2151 - val_accuracy: 0.7281\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1368 - accuracy: 0.9652 - val_loss: 2.1835 - val_accuracy: 0.6940\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2245 - accuracy: 0.9606 - val_loss: 1.9744 - val_accuracy: 0.7114\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1277 - accuracy: 0.9688 - val_loss: 2.1564 - val_accuracy: 0.7166\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1317 - accuracy: 0.9664 - val_loss: 2.1672 - val_accuracy: 0.7287\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1453 - accuracy: 0.9661 - val_loss: 2.2582 - val_accuracy: 0.7222\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1514 - accuracy: 0.9668 - val_loss: 1.5230 - val_accuracy: 0.7307\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1319 - accuracy: 0.9674 - val_loss: 2.4883 - val_accuracy: 0.7191\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1417 - accuracy: 0.9664 - val_loss: 1.9959 - val_accuracy: 0.7339\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1331 - accuracy: 0.9668 - val_loss: 2.1319 - val_accuracy: 0.7372\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1367 - accuracy: 0.9667 - val_loss: 1.8732 - val_accuracy: 0.7364\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1359 - accuracy: 0.9691 - val_loss: 1.7330 - val_accuracy: 0.7387\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1372 - accuracy: 0.9686 - val_loss: 2.0116 - val_accuracy: 0.7224\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1587 - accuracy: 0.9642 - val_loss: 2.0238 - val_accuracy: 0.7189\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1462 - accuracy: 0.9662 - val_loss: 2.7245 - val_accuracy: 0.6771\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1453 - accuracy: 0.9669 - val_loss: 2.0572 - val_accuracy: 0.7461\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1513 - accuracy: 0.9663 - val_loss: 3.8182 - val_accuracy: 0.6962\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1544 - accuracy: 0.9664 - val_loss: 2.7620 - val_accuracy: 0.7163\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1707 - accuracy: 0.9640 - val_loss: 3.4907 - val_accuracy: 0.6354\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1597 - accuracy: 0.9644 - val_loss: 2.3757 - val_accuracy: 0.7520\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1918 - accuracy: 0.9632 - val_loss: 4.5135 - val_accuracy: 0.6680\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1712 - accuracy: 0.9622 - val_loss: 1.6329 - val_accuracy: 0.7420\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1419 - accuracy: 0.9684 - val_loss: 3.2407 - val_accuracy: 0.7484\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2189 - accuracy: 0.9637 - val_loss: 2.4751 - val_accuracy: 0.7273\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1750 - accuracy: 0.9647 - val_loss: 2.6434 - val_accuracy: 0.7279\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1718 - accuracy: 0.9622 - val_loss: 2.8325 - val_accuracy: 0.7385\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1948 - accuracy: 0.9611 - val_loss: 6.1338 - val_accuracy: 0.6467\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1464 - accuracy: 0.9687 - val_loss: 3.1076 - val_accuracy: 0.7388\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1651 - accuracy: 0.9646 - val_loss: 6.3419 - val_accuracy: 0.7020\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2062 - accuracy: 0.9596 - val_loss: 2.1479 - val_accuracy: 0.7292\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2401 - accuracy: 0.9635 - val_loss: 2.0641 - val_accuracy: 0.7290\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1619 - accuracy: 0.9681 - val_loss: 2.2943 - val_accuracy: 0.7297\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1919 - accuracy: 0.9603 - val_loss: 1.7152 - val_accuracy: 0.7447\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2097 - accuracy: 0.9598 - val_loss: 1.7233 - val_accuracy: 0.7222\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2453 - accuracy: 0.9539 - val_loss: 3.2837 - val_accuracy: 0.6715\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1874 - accuracy: 0.9609 - val_loss: 1.7766 - val_accuracy: 0.7292\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1729 - accuracy: 0.9642 - val_loss: 3.8001 - val_accuracy: 0.6662\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1825 - accuracy: 0.9622 - val_loss: 1.5057 - val_accuracy: 0.7100\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2116 - accuracy: 0.9581 - val_loss: 4.1291 - val_accuracy: 0.6385\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2009 - accuracy: 0.9591 - val_loss: 1.6936 - val_accuracy: 0.7383\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1900 - accuracy: 0.9602 - val_loss: 2.1708 - val_accuracy: 0.7281\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1920 - accuracy: 0.9603 - val_loss: 2.7403 - val_accuracy: 0.7164\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2306 - accuracy: 0.9585 - val_loss: 2.6195 - val_accuracy: 0.7374\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1672 - accuracy: 0.9642 - val_loss: 2.0165 - val_accuracy: 0.6951\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1787 - accuracy: 0.9633 - val_loss: 4.3454 - val_accuracy: 0.7186\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1948 - accuracy: 0.9614 - val_loss: 54.4452 - val_accuracy: 0.6060\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2776 - accuracy: 0.9531 - val_loss: 2.4461 - val_accuracy: 0.7502\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1834 - accuracy: 0.9647 - val_loss: 2.1662 - val_accuracy: 0.6727\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2465 - accuracy: 0.9546 - val_loss: 2.4656 - val_accuracy: 0.7189\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2796 - accuracy: 0.9524 - val_loss: 2.3260 - val_accuracy: 0.6972\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2456 - accuracy: 0.9489 - val_loss: 2.1368 - val_accuracy: 0.7328\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1955 - accuracy: 0.9601 - val_loss: 2.9058 - val_accuracy: 0.7409\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2593 - accuracy: 0.9505 - val_loss: 2.1215 - val_accuracy: 0.7270\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3710 - accuracy: 0.9409 - val_loss: 1.7567 - val_accuracy: 0.6351\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6015 - accuracy: 0.9347 - val_loss: 2.0005 - val_accuracy: 0.7373\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3270 - accuracy: 0.9432 - val_loss: 2.5981 - val_accuracy: 0.5951\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2355 - accuracy: 0.9513 - val_loss: 3.7834 - val_accuracy: 0.5423\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2765 - accuracy: 0.9455 - val_loss: 3.3272 - val_accuracy: 0.6506\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3294 - accuracy: 0.9342 - val_loss: 1.9857 - val_accuracy: 0.7449\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3651 - accuracy: 0.9290 - val_loss: 2.0502 - val_accuracy: 0.7473\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2720 - accuracy: 0.9433 - val_loss: 3.6791 - val_accuracy: 0.7118\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3054 - accuracy: 0.9455 - val_loss: 1.9448 - val_accuracy: 0.7379\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3837 - accuracy: 0.9310 - val_loss: 3.5666 - val_accuracy: 0.7068\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3963 - accuracy: 0.9278 - val_loss: 1.9478 - val_accuracy: 0.7188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEJJECAKDllo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_rms_2.save('model_rms_2.h5')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJFOk3slDrQB",
        "colab_type": "text"
      },
      "source": [
        "ADADELTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0isbpBu5Dqej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "037f19b8-5c0f-4466-96d5-7b19b27cdfac"
      },
      "source": [
        "model_adadelta_2 = get_new_model_architecture()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEhtM-IJD87Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bf836d0-6a1b-434a-a3ae-3966d648db70"
      },
      "source": [
        "model_adadelta_2.summary()\n",
        "adadelta = keras.optimizers.Adadelta()\n",
        "model_adadelta_2.compile(loss='sparse_categorical_crossentropy', optimizer=adadelta, metrics=['accuracy'])\n",
        "history_adadelta_2 = model_adadelta_2.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 1,480,824\n",
            "Trainable params: 1,480,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.3033 - accuracy: 0.0964 - val_loss: 2.3032 - val_accuracy: 0.0986\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3030 - accuracy: 0.0993 - val_loss: 2.3029 - val_accuracy: 0.0991\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0994\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3025 - accuracy: 0.1000 - val_loss: 2.3025 - val_accuracy: 0.0999\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3024 - accuracy: 0.1001 - val_loss: 2.3023 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3022 - accuracy: 0.1001 - val_loss: 2.3021 - val_accuracy: 0.1001\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3020 - accuracy: 0.1000 - val_loss: 2.3020 - val_accuracy: 0.1002\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3019 - accuracy: 0.1001 - val_loss: 2.3018 - val_accuracy: 0.1006\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3017 - accuracy: 0.1003 - val_loss: 2.3016 - val_accuracy: 0.1015\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3015 - accuracy: 0.1012 - val_loss: 2.3015 - val_accuracy: 0.1031\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3014 - accuracy: 0.1021 - val_loss: 2.3013 - val_accuracy: 0.1039\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3012 - accuracy: 0.1033 - val_loss: 2.3011 - val_accuracy: 0.1047\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3010 - accuracy: 0.1043 - val_loss: 2.3009 - val_accuracy: 0.1049\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3008 - accuracy: 0.1053 - val_loss: 2.3007 - val_accuracy: 0.1056\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3006 - accuracy: 0.1066 - val_loss: 2.3005 - val_accuracy: 0.1050\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3004 - accuracy: 0.1069 - val_loss: 2.3003 - val_accuracy: 0.1057\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3002 - accuracy: 0.1072 - val_loss: 2.3001 - val_accuracy: 0.1075\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.3000 - accuracy: 0.1083 - val_loss: 2.2999 - val_accuracy: 0.1080\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2998 - accuracy: 0.1090 - val_loss: 2.2997 - val_accuracy: 0.1093\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2995 - accuracy: 0.1099 - val_loss: 2.2994 - val_accuracy: 0.1098\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2993 - accuracy: 0.1098 - val_loss: 2.2992 - val_accuracy: 0.1102\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2990 - accuracy: 0.1113 - val_loss: 2.2989 - val_accuracy: 0.1107\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2988 - accuracy: 0.1115 - val_loss: 2.2986 - val_accuracy: 0.1110\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2985 - accuracy: 0.1119 - val_loss: 2.2983 - val_accuracy: 0.1129\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2982 - accuracy: 0.1123 - val_loss: 2.2980 - val_accuracy: 0.1132\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2979 - accuracy: 0.1131 - val_loss: 2.2977 - val_accuracy: 0.1132\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2975 - accuracy: 0.1132 - val_loss: 2.2974 - val_accuracy: 0.1138\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2972 - accuracy: 0.1142 - val_loss: 2.2970 - val_accuracy: 0.1136\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2968 - accuracy: 0.1142 - val_loss: 2.2966 - val_accuracy: 0.1150\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2964 - accuracy: 0.1146 - val_loss: 2.2962 - val_accuracy: 0.1155\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2960 - accuracy: 0.1152 - val_loss: 2.2958 - val_accuracy: 0.1165\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2956 - accuracy: 0.1157 - val_loss: 2.2954 - val_accuracy: 0.1171\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2951 - accuracy: 0.1164 - val_loss: 2.2949 - val_accuracy: 0.1169\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2947 - accuracy: 0.1171 - val_loss: 2.2944 - val_accuracy: 0.1172\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2942 - accuracy: 0.1181 - val_loss: 2.2939 - val_accuracy: 0.1173\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2936 - accuracy: 0.1185 - val_loss: 2.2934 - val_accuracy: 0.1188\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2931 - accuracy: 0.1202 - val_loss: 2.2928 - val_accuracy: 0.1202\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2925 - accuracy: 0.1213 - val_loss: 2.2922 - val_accuracy: 0.1190\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2919 - accuracy: 0.1214 - val_loss: 2.2916 - val_accuracy: 0.1233\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2913 - accuracy: 0.1239 - val_loss: 2.2910 - val_accuracy: 0.1224\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2906 - accuracy: 0.1236 - val_loss: 2.2903 - val_accuracy: 0.1240\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2900 - accuracy: 0.1246 - val_loss: 2.2897 - val_accuracy: 0.1255\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2893 - accuracy: 0.1255 - val_loss: 2.2890 - val_accuracy: 0.1252\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2886 - accuracy: 0.1260 - val_loss: 2.2883 - val_accuracy: 0.1278\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2879 - accuracy: 0.1274 - val_loss: 2.2875 - val_accuracy: 0.1278\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2871 - accuracy: 0.1281 - val_loss: 2.2868 - val_accuracy: 0.1267\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2863 - accuracy: 0.1289 - val_loss: 2.2860 - val_accuracy: 0.1322\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2856 - accuracy: 0.1298 - val_loss: 2.2852 - val_accuracy: 0.1326\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2847 - accuracy: 0.1302 - val_loss: 2.2844 - val_accuracy: 0.1344\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2839 - accuracy: 0.1316 - val_loss: 2.2835 - val_accuracy: 0.1321\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2831 - accuracy: 0.1313 - val_loss: 2.2827 - val_accuracy: 0.1365\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2822 - accuracy: 0.1335 - val_loss: 2.2817 - val_accuracy: 0.1348\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2813 - accuracy: 0.1338 - val_loss: 2.2808 - val_accuracy: 0.1362\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2803 - accuracy: 0.1352 - val_loss: 2.2798 - val_accuracy: 0.1371\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2793 - accuracy: 0.1355 - val_loss: 2.2788 - val_accuracy: 0.1394\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2783 - accuracy: 0.1374 - val_loss: 2.2778 - val_accuracy: 0.1392\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2773 - accuracy: 0.1388 - val_loss: 2.2767 - val_accuracy: 0.1410\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2762 - accuracy: 0.1409 - val_loss: 2.2757 - val_accuracy: 0.1401\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2752 - accuracy: 0.1422 - val_loss: 2.2747 - val_accuracy: 0.1396\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2741 - accuracy: 0.1429 - val_loss: 2.2734 - val_accuracy: 0.1427\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2730 - accuracy: 0.1453 - val_loss: 2.2724 - val_accuracy: 0.1419\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2718 - accuracy: 0.1462 - val_loss: 2.2712 - val_accuracy: 0.1459\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2706 - accuracy: 0.1479 - val_loss: 2.2700 - val_accuracy: 0.1434\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2695 - accuracy: 0.1486 - val_loss: 2.2688 - val_accuracy: 0.1481\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2682 - accuracy: 0.1505 - val_loss: 2.2675 - val_accuracy: 0.1507\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2670 - accuracy: 0.1513 - val_loss: 2.2663 - val_accuracy: 0.1519\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2656 - accuracy: 0.1528 - val_loss: 2.2651 - val_accuracy: 0.1567\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2644 - accuracy: 0.1552 - val_loss: 2.2636 - val_accuracy: 0.1526\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2630 - accuracy: 0.1551 - val_loss: 2.2622 - val_accuracy: 0.1567\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2617 - accuracy: 0.1568 - val_loss: 2.2609 - val_accuracy: 0.1586\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2603 - accuracy: 0.1568 - val_loss: 2.2595 - val_accuracy: 0.1573\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2589 - accuracy: 0.1581 - val_loss: 2.2580 - val_accuracy: 0.1590\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2574 - accuracy: 0.1597 - val_loss: 2.2566 - val_accuracy: 0.1599\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2561 - accuracy: 0.1602 - val_loss: 2.2552 - val_accuracy: 0.1614\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2546 - accuracy: 0.1601 - val_loss: 2.2539 - val_accuracy: 0.1592\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2531 - accuracy: 0.1620 - val_loss: 2.2523 - val_accuracy: 0.1630\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2516 - accuracy: 0.1618 - val_loss: 2.2508 - val_accuracy: 0.1619\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2502 - accuracy: 0.1629 - val_loss: 2.2494 - val_accuracy: 0.1641\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2487 - accuracy: 0.1638 - val_loss: 2.2478 - val_accuracy: 0.1650\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2472 - accuracy: 0.1632 - val_loss: 2.2464 - val_accuracy: 0.1659\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2457 - accuracy: 0.1638 - val_loss: 2.2451 - val_accuracy: 0.1661\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2442 - accuracy: 0.1637 - val_loss: 2.2433 - val_accuracy: 0.1662\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2426 - accuracy: 0.1650 - val_loss: 2.2419 - val_accuracy: 0.1658\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2410 - accuracy: 0.1652 - val_loss: 2.2401 - val_accuracy: 0.1664\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2395 - accuracy: 0.1655 - val_loss: 2.2387 - val_accuracy: 0.1683\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2379 - accuracy: 0.1654 - val_loss: 2.2374 - val_accuracy: 0.1697\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2362 - accuracy: 0.1661 - val_loss: 2.2352 - val_accuracy: 0.1687\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2346 - accuracy: 0.1668 - val_loss: 2.2336 - val_accuracy: 0.1698\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2328 - accuracy: 0.1680 - val_loss: 2.2318 - val_accuracy: 0.1688\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2311 - accuracy: 0.1681 - val_loss: 2.2301 - val_accuracy: 0.1713\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2292 - accuracy: 0.1685 - val_loss: 2.2288 - val_accuracy: 0.1688\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2276 - accuracy: 0.1698 - val_loss: 2.2266 - val_accuracy: 0.1718\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2258 - accuracy: 0.1691 - val_loss: 2.2249 - val_accuracy: 0.1709\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2241 - accuracy: 0.1704 - val_loss: 2.2233 - val_accuracy: 0.1719\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2223 - accuracy: 0.1711 - val_loss: 2.2213 - val_accuracy: 0.1746\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2205 - accuracy: 0.1706 - val_loss: 2.2195 - val_accuracy: 0.1737\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2188 - accuracy: 0.1728 - val_loss: 2.2180 - val_accuracy: 0.1743\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2170 - accuracy: 0.1729 - val_loss: 2.2160 - val_accuracy: 0.1756\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2151 - accuracy: 0.1731 - val_loss: 2.2143 - val_accuracy: 0.1733\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2133 - accuracy: 0.1731 - val_loss: 2.2125 - val_accuracy: 0.1738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7KOa65aD71O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adadelta_2.save('model_adadelta_2.h5')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge4JgJkMEB-7",
        "colab_type": "text"
      },
      "source": [
        "Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwq5kxNdEHoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec4087c6-d0f8-4ecd-ddbf-87080a56dbe4"
      },
      "source": [
        "model_adagrad_2 = get_new_model_architecture()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized. Please compile before training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxP7IhmvEK1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8f72980-4dd0-48e6-935a-308577e329db"
      },
      "source": [
        "model_adagrad_2.summary()\n",
        "adagrad = keras.optimizers.Adagrad()\n",
        "model_adagrad_2.compile(loss='sparse_categorical_crossentropy', optimizer=adagrad, metrics=['accuracy'])\n",
        "history_adagrad_2= model_adagrad_2.fit(X_train, y_train, batch_size=batch_size, \n",
        "                              epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 1,480,824\n",
            "Trainable params: 1,480,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.3016 - accuracy: 0.1116 - val_loss: 2.3009 - val_accuracy: 0.1095\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2997 - accuracy: 0.1143 - val_loss: 2.2986 - val_accuracy: 0.1124\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2968 - accuracy: 0.1140 - val_loss: 2.2953 - val_accuracy: 0.1100\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2923 - accuracy: 0.1110 - val_loss: 2.2897 - val_accuracy: 0.1081\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2836 - accuracy: 0.1107 - val_loss: 2.2776 - val_accuracy: 0.1052\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.2644 - accuracy: 0.1112 - val_loss: 2.2513 - val_accuracy: 0.1083\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.2279 - accuracy: 0.1176 - val_loss: 2.2082 - val_accuracy: 0.1236\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 2.1792 - accuracy: 0.1692 - val_loss: 2.1545 - val_accuracy: 0.1986\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.1228 - accuracy: 0.2156 - val_loss: 2.0868 - val_accuracy: 0.2302\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0660 - accuracy: 0.2385 - val_loss: 2.0296 - val_accuracy: 0.2545\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.0127 - accuracy: 0.2609 - val_loss: 1.9707 - val_accuracy: 0.2824\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9598 - accuracy: 0.2825 - val_loss: 2.0188 - val_accuracy: 0.2728\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.9148 - accuracy: 0.3066 - val_loss: 1.9246 - val_accuracy: 0.3187\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8761 - accuracy: 0.3204 - val_loss: 1.8409 - val_accuracy: 0.3340\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.8383 - accuracy: 0.3376 - val_loss: 1.8325 - val_accuracy: 0.3287\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.8043 - accuracy: 0.3508 - val_loss: 1.8053 - val_accuracy: 0.3517\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.7702 - accuracy: 0.3636 - val_loss: 1.7454 - val_accuracy: 0.3719\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.7441 - accuracy: 0.3728 - val_loss: 1.7427 - val_accuracy: 0.3669\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.7206 - accuracy: 0.3836 - val_loss: 1.7280 - val_accuracy: 0.3812\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6945 - accuracy: 0.3931 - val_loss: 1.7327 - val_accuracy: 0.3753\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6764 - accuracy: 0.3972 - val_loss: 1.6667 - val_accuracy: 0.4036\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6590 - accuracy: 0.4040 - val_loss: 1.7317 - val_accuracy: 0.3727\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6403 - accuracy: 0.4111 - val_loss: 1.6412 - val_accuracy: 0.4057\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6262 - accuracy: 0.4182 - val_loss: 1.6361 - val_accuracy: 0.4145\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6134 - accuracy: 0.4228 - val_loss: 1.6174 - val_accuracy: 0.4162\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6005 - accuracy: 0.4232 - val_loss: 1.6058 - val_accuracy: 0.4158\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5881 - accuracy: 0.4283 - val_loss: 1.5977 - val_accuracy: 0.4200\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5747 - accuracy: 0.4330 - val_loss: 1.5817 - val_accuracy: 0.4295\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5656 - accuracy: 0.4369 - val_loss: 1.5846 - val_accuracy: 0.4265\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5526 - accuracy: 0.4429 - val_loss: 1.5555 - val_accuracy: 0.4348\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5442 - accuracy: 0.4460 - val_loss: 1.5981 - val_accuracy: 0.4228\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5352 - accuracy: 0.4469 - val_loss: 1.5415 - val_accuracy: 0.4412\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5270 - accuracy: 0.4515 - val_loss: 1.5526 - val_accuracy: 0.4455\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5187 - accuracy: 0.4530 - val_loss: 1.5233 - val_accuracy: 0.4533\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5086 - accuracy: 0.4563 - val_loss: 1.5250 - val_accuracy: 0.4400\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5019 - accuracy: 0.4583 - val_loss: 1.5032 - val_accuracy: 0.4590\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4935 - accuracy: 0.4624 - val_loss: 1.5205 - val_accuracy: 0.4545\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4851 - accuracy: 0.4655 - val_loss: 1.5660 - val_accuracy: 0.4238\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4822 - accuracy: 0.4666 - val_loss: 1.4975 - val_accuracy: 0.4600\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4733 - accuracy: 0.4697 - val_loss: 1.5273 - val_accuracy: 0.4530\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4666 - accuracy: 0.4700 - val_loss: 1.4930 - val_accuracy: 0.4606\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4608 - accuracy: 0.4751 - val_loss: 1.4791 - val_accuracy: 0.4673\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4556 - accuracy: 0.4739 - val_loss: 1.4648 - val_accuracy: 0.4755\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4496 - accuracy: 0.4803 - val_loss: 1.4770 - val_accuracy: 0.4648\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4438 - accuracy: 0.4792 - val_loss: 1.4850 - val_accuracy: 0.4622\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4385 - accuracy: 0.4814 - val_loss: 1.4880 - val_accuracy: 0.4663\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4329 - accuracy: 0.4843 - val_loss: 1.4860 - val_accuracy: 0.4578\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4274 - accuracy: 0.4868 - val_loss: 1.4484 - val_accuracy: 0.4805\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4204 - accuracy: 0.4878 - val_loss: 1.4518 - val_accuracy: 0.4756\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4146 - accuracy: 0.4912 - val_loss: 1.4540 - val_accuracy: 0.4745\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4108 - accuracy: 0.4915 - val_loss: 1.4748 - val_accuracy: 0.4672\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4072 - accuracy: 0.4929 - val_loss: 1.4466 - val_accuracy: 0.4829\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4026 - accuracy: 0.4947 - val_loss: 1.4305 - val_accuracy: 0.4829\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3953 - accuracy: 0.4975 - val_loss: 1.4273 - val_accuracy: 0.4837\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3915 - accuracy: 0.4988 - val_loss: 1.4153 - val_accuracy: 0.4900\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3863 - accuracy: 0.5012 - val_loss: 1.4277 - val_accuracy: 0.4878\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3814 - accuracy: 0.5033 - val_loss: 1.4180 - val_accuracy: 0.4839\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3766 - accuracy: 0.5055 - val_loss: 1.4310 - val_accuracy: 0.4811\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3735 - accuracy: 0.5055 - val_loss: 1.4094 - val_accuracy: 0.4929\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3692 - accuracy: 0.5098 - val_loss: 1.4236 - val_accuracy: 0.4875\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3624 - accuracy: 0.5118 - val_loss: 1.3919 - val_accuracy: 0.4979\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3592 - accuracy: 0.5133 - val_loss: 1.4018 - val_accuracy: 0.4988\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3539 - accuracy: 0.5135 - val_loss: 1.3915 - val_accuracy: 0.4998\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3513 - accuracy: 0.5153 - val_loss: 1.3906 - val_accuracy: 0.4962\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3450 - accuracy: 0.5172 - val_loss: 1.3991 - val_accuracy: 0.4926\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3427 - accuracy: 0.5180 - val_loss: 1.4005 - val_accuracy: 0.4974\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3392 - accuracy: 0.5201 - val_loss: 1.4319 - val_accuracy: 0.4909\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3339 - accuracy: 0.5216 - val_loss: 1.3806 - val_accuracy: 0.5068\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3307 - accuracy: 0.5244 - val_loss: 1.3864 - val_accuracy: 0.5021\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3257 - accuracy: 0.5242 - val_loss: 1.4250 - val_accuracy: 0.4960\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3215 - accuracy: 0.5258 - val_loss: 1.3653 - val_accuracy: 0.5090\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3183 - accuracy: 0.5295 - val_loss: 1.3593 - val_accuracy: 0.5122\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3139 - accuracy: 0.5288 - val_loss: 1.4171 - val_accuracy: 0.4891\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3104 - accuracy: 0.5320 - val_loss: 1.3735 - val_accuracy: 0.5045\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.3058 - accuracy: 0.5328 - val_loss: 1.3676 - val_accuracy: 0.5083\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.3013 - accuracy: 0.5336 - val_loss: 1.3577 - val_accuracy: 0.5147\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2979 - accuracy: 0.5363 - val_loss: 1.3587 - val_accuracy: 0.5133\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2946 - accuracy: 0.5353 - val_loss: 1.3458 - val_accuracy: 0.5181\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2902 - accuracy: 0.5384 - val_loss: 1.3441 - val_accuracy: 0.5205\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2872 - accuracy: 0.5408 - val_loss: 1.3438 - val_accuracy: 0.5191\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2834 - accuracy: 0.5418 - val_loss: 1.3432 - val_accuracy: 0.5179\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2803 - accuracy: 0.5419 - val_loss: 1.3548 - val_accuracy: 0.5164\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2769 - accuracy: 0.5459 - val_loss: 1.3847 - val_accuracy: 0.5001\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2727 - accuracy: 0.5449 - val_loss: 1.3281 - val_accuracy: 0.5237\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2683 - accuracy: 0.5479 - val_loss: 1.3464 - val_accuracy: 0.5172\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2654 - accuracy: 0.5478 - val_loss: 1.3243 - val_accuracy: 0.5246\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2634 - accuracy: 0.5478 - val_loss: 1.3594 - val_accuracy: 0.5096\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2581 - accuracy: 0.5517 - val_loss: 1.3486 - val_accuracy: 0.5183\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2562 - accuracy: 0.5521 - val_loss: 1.3253 - val_accuracy: 0.5273\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2510 - accuracy: 0.5527 - val_loss: 1.3310 - val_accuracy: 0.5235\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2491 - accuracy: 0.5537 - val_loss: 1.3120 - val_accuracy: 0.5316\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2468 - accuracy: 0.5535 - val_loss: 1.3219 - val_accuracy: 0.5257\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2424 - accuracy: 0.5579 - val_loss: 1.3232 - val_accuracy: 0.5250\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2390 - accuracy: 0.5564 - val_loss: 1.3101 - val_accuracy: 0.5360\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2368 - accuracy: 0.5591 - val_loss: 1.3407 - val_accuracy: 0.5218\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2316 - accuracy: 0.5598 - val_loss: 1.3085 - val_accuracy: 0.5293\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2287 - accuracy: 0.5611 - val_loss: 1.3267 - val_accuracy: 0.5220\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2234 - accuracy: 0.5640 - val_loss: 1.2989 - val_accuracy: 0.5390\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2211 - accuracy: 0.5644 - val_loss: 1.3107 - val_accuracy: 0.5326\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2198 - accuracy: 0.5666 - val_loss: 1.3016 - val_accuracy: 0.5395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpHS-Cw_EPwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_adagrad_2.save('model_adagrad_2.h5')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWBR6oU6EY2u",
        "colab_type": "text"
      },
      "source": [
        "Accuracy plot of new Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lY7s9_jETjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "088c36c1-dcd4-4f76-dbcb-5d3b761ab693"
      },
      "source": [
        "# Combined Training Accuracy Plot\n",
        "\n",
        "plt.plot(history_sgd_plain_2.history['accuracy'])\n",
        "plt.plot(history_adam_2.history['accuracy'])\n",
        "plt.plot(history_rmsprop_2.history['accuracy'])\n",
        "plt.plot(history_adadelta_2.history['accuracy'])\n",
        "plt.plot(history_adagrad_2.history['accuracy'])\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad'])\n",
        "plt.savefig('Combined-Accuracy_2.jpg', dpi=200)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbP13zySP0ad",
        "colab_type": "text"
      },
      "source": [
        "**ADAGRAD**\n",
        "1. Adaptive learning rate method. We adapt learning rates according to the parameters. \n",
        "2. We perform larger updates for infrequent parameters and smaller updates for frequent parameters.\n",
        "3. Different learning rate for every parameter theta at every time step t.\n",
        "4. Eliminates need to manually update learning rate.\n",
        "5. The learning rate is inversely affected by the sum of the square of the past gradients.\n",
        "6. Each term is a positive term so it keeps on growing to make the learning rate  infinitesimally small to the point that algorithm is no longer able learning. \n",
        "7. Adadelta, RMSProp, and adam tries to resolve Adagrads radically diminishing learning rates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IR8pgdXRdHT",
        "colab_type": "text"
      },
      "source": [
        "**ADADELTA**\n",
        "1. Adadelta is an extension of Adagrad and it also tries to reduce Adagrads aggressive, monotonically reducing the learning rate.\n",
        "2. It does this by restricting the window of the past accumulated gradient to some fixed size of w. Running average at time t then depends on the previous average and the current gradient.\n",
        "3. In Adadelta we do not need to set the default learning rate as we take the ratio of the running average of the previous time steps to the current gradient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXKCCiCiR24X",
        "colab_type": "text"
      },
      "source": [
        "**RMSProp**\n",
        "1. RMSProp is Root Mean Square Propagation.\n",
        "2. RMSProp tries to resolve Adagrads radically diminishing learning rates by using a moving average of the squared gradient. It utilizes the magnitude of the recent gradient descents to normalize the gradient.\n",
        "3. In RMSProp learning rate gets adjusted automatically and it chooses a different learning rate for each parameter.\n",
        "4. RMSProp divides the learning rate by the average of the exponential decay of squared gradients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXCW-IvHSeJ7",
        "colab_type": "text"
      },
      "source": [
        "**ADAM**\n",
        "1. ADAM can be viewed as a combination of ADAGRAD and RMSprop.\n",
        "2. Adam implements the exponential moving average of the gradients to scale the learning rate instead of a simple average as in Adagrad. It keeps an exponentially decaying average of past gradients\n",
        "3. Adam is computationally efficient and has very little memory requirement.\n",
        "4. Adam optimizer is one of the most popular gradient descent optimization algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRVBTH8QTv2W",
        "colab_type": "text"
      },
      "source": [
        "**COMPARING TRAINING CURVES OF DIFFERENT OPTIMIZERS**\n",
        "\n",
        "\n",
        "1.  Steps until convergence : ADAM and RMSprop performed almost same when it comes to convergence. SGD converged later bit after convergence accuracy is more. ADAGRAD and ADADELTA also converged faster as compared to SGD but accuracy of ADADELTA fluctuates a little before converging.\n",
        "2.  Training accuracy (or loss) when converged: After convergence SGD shows highest accuracy followed by RMSProp and ADAM which performed similarly. ADADELTA and ADAGRAD have lower accuracy may be because of diminishing learning rate.\n",
        "3.  Stability of training (fluctuation of the curve): After converging curves of ADADELTA, ADAGRAD and SGD are almost stable but minor fluctuations can be seen in curves of RMSProp and ADAM.\n",
        "\n",
        "**COMPARISON OF DIFFERENT ARCHITECTURES**\n",
        "Overall the different optimizers performed similarly on both archotectures but the RMSProp fluctuates more in Architecture 2 which contains more hidden layers. It could be bacause of using a moving average of the squared gradient. RMSProp utilizes the magnitude of the recent gradient descents to normalize the gradient.\n",
        "\n",
        "\n"
      ]
    }
  ]
}