{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_assn_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qPCRXB8OQZq"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy1ZGUVAOVS8",
        "outputId": "f2c08e01-a876-4420-e499-db4162fe00b8"
      },
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGhKC3ZZOeDU"
      },
      "source": [
        "# GRADED FUNCTION: zero_pad\n",
        "\n",
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "    as illustrated in Figure 1.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 1 line)\n",
        "    X_pad = np.pad(X, ((0,0), (pad, pad), (pad, pad), (0,0)), mode='constant', constant_values = (0,0))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_pad"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "6Igz-dMGQcc6",
        "outputId": "56676b0b-bcd9-483d-e432-6134f1809604"
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print (\"x.shape =\\n\", x.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[1,1] =\\n\", x[1,1])\n",
        "print (\"x_pad[1,1] =\\n\", x_pad[1,1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape =\n",
            " (4, 3, 3, 2)\n",
            "x_pad.shape =\n",
            " (4, 7, 7, 2)\n",
            "x[1,1] =\n",
            " [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] =\n",
            " [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f014d1d8510>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAADHCAYAAAAanejIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASGklEQVR4nO3dfbAddX3H8fen4YYQQIKEhzQJJNpMpqhoMEUQy1CQDiBD7EgdsD7gw2R0RKHaUbEz2DpTxf6hiFiYlMcUBrBANVWU0gGKTOUhxPAQAjZmsEkMTSAIJChJ4NM/zgZP7jN395495+7nNXMn+/A7+/uee3Y+d7O757eyTURETHx/UHcBERHRGQn8iIiGSOBHRDREAj8ioiES+BERDZHAj4hoiAR+RExYks6WdE/ddXSLBH5EREMk8CMiGiKB38MkvVHSFklHFvN/KGmzpONrLi0CGNs+KukuSV+XdL+k5yX9QNLr29b/q6SnJD0n6W5Jb2pbd4CkZcXr7gfeOJ7vr9ck8HuY7V8CXwSulTQVuAq4xvZdtRYWUSixj34Y+BgwA9gJXNy27sfAPOAgYAVwXdu67wK/K173seInCspYOr1P0jJgLmDgT2y/VHNJEbt5LfuopLuAe21/qZg/HFgJ7GX75X5tpwHPAtOArbTC/i22Hy/Wfw04zva7Kn9TPShH+BPDPwNvBr6TsI8u9Vr30XVt078C+oDpkiZJulDSLyU9DzxZtJkOHAjsMchro5DA73GS9gEuAq4A/q79XGdENxjjPjq7bfpQYAfwNPABYBHwbmA/YM6uboDNtE7/9H9tFBL4ve/bwHLbnwB+BFxWcz0R/Y1lH/2gpMOL8/5fBW4qTufsC7wEPANMBb626wXF+lto/VGZWpwK+ki1b6W3JfB7mKRFwMnAp4pFnwOOlPRX9VUV8Xsl9tF/Aa4GngKmAJ8tli+ldZpmA/AYcG+/150D7FO87mpaF4mjkIu2EdFViou219q+vO5aJpoc4UdENMQeZV5cXHy5kdaFkyeB99t+dpB2LwOPFLP/a/v0Mv1GRG+TtHWIVad0tJCGKXVKR9I/AltsXyjpS8D+tr84SLuttvcpUWdERJRUNvCfAI63vVHSDOAu2/MHaZfAj4ioWdlz+Afb3lhMPwUcPES7KZKWS7pX0ntL9hkREWMw4jl8Sf8JHDLIqr9tn7FtSUP9d+Ew2xskvQG4Q9IjxRgb/ftaDCwGmDqVt7/hjaUuMXSNXz2yb90lVGb7G/aqu4TKvLT210/bPrDT/fZN3ttTpu7f6W6jIX734rPs2L5Ng60bMVFtv3uodZL+T9KMtlM6m4bYxobi37XFLVcLgAGBb3sJsATgLUf0+fs/mj5SeT3hk4dNnGE8nrzwiLpLqMya919Qy9fup0zdnwV/+tmRG0aMwc9/evGQ68qe0lnG77/J9hHgB/0bSNpf0p7F9HTgWFpfmIiIiA4qG/gXAidJ+h9aY1tcCCBpoaRdX5r4Y2C5pIeAO4ELbSfwIyI6rNRJctvPACcOsnw58Ili+r+Bt5TpJyIiyss3bSMiGiKBHxHREAn8iJIknSzpCUlrim+cR3SlBH5ECZIm0XqO6inA4cBZxTjsEV0ngR9RzlHAGttrbW8HbqD1RKaIrpPAjyhnJrs/Q3V9sWw3khYXw4ss37F9W8eKi2iXwI/oANtLbC+0vbBv8t51lxMNlcCPKGcDuz80e1axLKLrJPAjynkAmCdprqTJwJm0hhyJ6DoTYzjKiJrY3inpHOA2YBJwpe1VNZcVMagEfkRJtm8Fbq27joiR5JRORERDJPAjIhoigR8R0RAJ/IiIhkjgR0Q0RAI/IqIhKgn8kYaHlbSnpBuL9fdJmlNFvxERMXqlA3+Uw8N+HHjW9h8B3wK+UbbfiIh4bao4wh/N8LCLgGuK6ZuAEyWpgr4jImKUqgj80QwP+2ob2zuB54AD+m+ofQjZLVteqaC0iIjYpasu2rYPIfv613dVaRERPa+KVB3N8LCvtpG0B7Af8EwFfUdExChVEfijGR52GfCRYvoM4A7brqDviIgYpdKBX5yT3zU87Grge7ZXSfqqpNOLZlcAB0haA3wOGHDrZkSvknSlpE2SHq27lojhVDI88mDDw9q+oG36d8BfVtFXRBe6GrgEWFpzHRHDypXRiJJs3w1sqbuOiJEk8CM6oP2W4x3bt9VdTjRUAj+iA9pvOe6bvHfd5URDJfAjIhoigR8R0RAJ/IiSJF0P/AyYL2m9pI/XXVPEYCq5LTOiyWyfVXcNEaORI/yIiIZI4EdENEQCPyKiIRL4ERENkcCPiGiI3KUTEcO66p++Vfk2P3nYuyrfJsCTNx4xLtudsXTPcdlup+UIPyKiIRL4ERENkcCPiGiISgJf0smSnpC0RtKAp1lJOlvSZkkri59PVNFvRESMXumLtpImAd8FTgLWAw9IWmb7sX5Nb7R9Ttn+IiJibKo4wj8KWGN7re3twA3Aogq2GxERFaritsyZwLq2+fXAOwZp9z5JxwG/AP7a9rr+DSQtBhYDHDpzD+b27VNBefV76rx31l1CZb5x5MR5bOv76i4gosM6ddH234E5to8AbgeuGaxR+1OBDjxgUodKixg7SbMl3SnpMUmrJJ1bd00RQ6ki8DcAs9vmZxXLXmX7GdsvFbOXA2+voN+IbrAT+Lztw4GjgU9LOrzmmiIGVUXgPwDMkzRX0mTgTGBZewNJM9pmTwdWV9BvRO1sb7S9oph+gda+PbPeqiIGV/ocvu2dks4BbgMmAVfaXiXpq8By28uAz0o6ndbR0Bbg7LL9RnQbSXOABcB9g6x79frUnntN62hdEbtUMpaO7VuBW/stu6Bt+nzg/Cr6iuhGkvYBbgbOs/18//W2lwBLAPadNssdLi8CyDdtI0qT1Ecr7K+zfUvd9UQMJYEfUYIkAVcAq21/s+56IoaTwI8o51jgQ8AJbUOHnFp3URGDyXj4ESXYvgdQ3XVEjEaO8CMiGiKBHxHREAn8iIiGSOBHRDREAj8ioiFyl05EDGs8hikfryHDx2v47ouWnjUu2+20HOFHRDREAj8ioiES+BERDZHAj4hoiAR+RERDJPAjIhqiksCXdKWkTZIeHWK9JF0saY2khyUdWUW/Ed1A0hRJ90t6qHiQ+d/XXVPEYKo6wr8aOHmY9acA84qfxcClFfUb0Q1eAk6w/VbgbcDJko6uuaaIASoJfNt303pW7VAWAUvdci8wrd+DzSN6VrFfby1m+4qfPMYwuk6nzuHPBNa1za8vlkVMCJImSVoJbAJutz3gQeYRdeuqi7aSFktaLmn55mderruciFGz/bLttwGzgKMkvbl9ffu+vWP7tnqKjMbrVOBvAGa3zc8qlu3G9hLbC20vPPCASR0qLaI6tn8D3Em/a1rt+3bf5L3rKS4ar1OBvwz4cHG3ztHAc7Y3dqjviHEl6UBJ04rpvYCTgMfrrSpioEpGy5R0PXA8MF3SeuArtC5cYfsy4FbgVGAN8CLw0Sr6jegSM4BrJE2idRD1Pds/rLmmiAEqCXzbw44datvAp6voK6Lb2H4YWFB3HREj6aqLthERMX4S+BERDZHAj4hoiAR+RERDJPAjIhoiDzGPiGG9552nV77N+dc+Ufk2AS77wF+My3Y5aHw222k5wo+IaIgEfkREQyTwIyIaIoEfEdEQCfyIiIZI4EdENEQCPyKiIRL4ERUoHnH4c0kZFjm6VgI/ohrnAqvrLiJiOAn8iJIkzQLeA1xedy0Rw0ngR5R3EfAF4JWhGuQh5tENKgl8SVdK2iTp0SHWHy/pOUkri58Lqug3om6STgM22X5wuHZ5iHl0g6oGT7sauARYOkybn9o+raL+IrrFscDpkk4FpgCvk3St7Q/WXFfEAJUc4du+G9hSxbYieont823Psj0HOBO4I2Ef3aqTwyMfI+kh4NfA39he1b+BpMXAYoApk/Ydl2FZ6zBeQ8HWYdyGn63FyroLiOioTgX+CuAw21uL//p+H5jXv5HtJcASgP32PMQdqi2iErbvAu6quYyIIXXkLh3bz9veWkzfCvRJmt6JviMioqUjgS/pEEkqpo8q+n2mE31HRERLJad0JF0PHA9Ml7Qe+ArQB2D7MuAM4FOSdgK/Bc60nVM2EREdVEng2z5rhPWX0LptMyIiapJv2kZENEQnb8uMiB607U0HV7/Nr1e+yZaDxmm7E0SO8CMiGiKBHxHREAn8iIiGSOBHRDREAj8ioiES+BERDZHAj4hoiNyHH1EBSU8CLwAvAzttL6y3ooiBEvgR1fkz20/XXUTEUHJKJyKiIRL4EdUw8B+SHiye3LYbSYslLZe0fMf2bTWUF5FTOhFVeZftDZIOAm6X9HjxrGdg96e57TttVoYGj1rkCD+iArY3FP9uAv4NOKreiiIGSuBHlCRpb0n77poG/hx4tN6qIgYqHfiSZku6U9JjklZJOneQNpJ0saQ1kh6WdGTZfiO6yMHAPZIeAu4HfmT7JzXXFDFAFefwdwKft72iOMp5UNLtth9ra3MKMK/4eQdwafFvRM+zvRZ4a911RIyk9BG+7Y22VxTTLwCrgZn9mi0ClrrlXmCapBll+46IiNGr9By+pDnAAuC+fqtmAuva5tcz8I/CbreubX/5xSpLi4hovMoCX9I+wM3AebafH8s2bC+xvdD2wsmTplZVWkREUFHgS+qjFfbX2b5lkCYbgNlt87OKZRER0SFV3KUj4Apgte1vDtFsGfDh4m6do4HnbG8s23dERIxeFXfpHAt8CHhE0spi2ZeBQwFsXwbcCpwKrAFeBD5aQb8REfEalA582/cAGqGNgU+X7SsiIsYu37SNiGiIBH5EREMk8CMiGiKBHxHREAn8iIiGSOBHRDREAj+iJEnTJN0k6XFJqyUdU3dNEYPJIw4jyvs28BPbZ0iaDGQgqOhKCfyIEiTtBxwHnA1gezuwvc6aIoaSUzoR5cwFNgNXSfq5pMuLxxzupn3o7x3bt3W+yggS+BFl7QEcCVxqewGwDfhS/0btQ3/3TR7w9yCiIxL4EeWsB9bb3vXQn5to/QGI6DoJ/IgSbD8FrJM0v1h0IvDYMC+JqE0u2kaU9xnguuIOnbVk+O/oUgn8iJJsrwQW1l1HxEhySicioiGqeMThbEl3SnpM0ipJ5w7S5nhJz0laWfxcULbfiIh4bao4pbMT+LztFZL2BR6UdLvt/heufmr7tAr6i4iIMSh9hG97o+0VxfQLwGpgZtntRkREtSo9hy9pDrAAuG+Q1cdIekjSjyW9qcp+IyJiZGo9X7yCDUn7AP8F/IPtW/qtex3wiu2tkk4Fvm173iDbWAwsLmbnA09UUtzwpgNPd6CfTpgo76VT7+Mw2wd2oJ/dSNoM/GqUzXvpM+2lWqG36n0ttQ65X1cS+JL6gB8Ct9n+5ijaPwkstF37L1vSctsT4pa6ifJeJsr7qEIv/S56qVborXqrqrWKu3QEXAGsHirsJR1StEPSUUW/z5TtOyIiRq+Ku3SOBT4EPCJpZbHsy8ChALYvA84APiVpJ/Bb4ExXdS4pIiJGpXTg274H0AhtLgEuKdvXOFlSdwEVmijvZaK8jyr00u+il2qF3qq3kloru2gbERHdLUMrREQ0RGMDX9LJkp6QtEbSgAdW9ApJV0raJOnRumspazTDdDRFL+2fvfi5SZpUPKHsh3XXMhJJ0yTdJOlxSaslHTPmbTXxlI6kScAvgJNoPcDiAeCsQYaD6HqSjgO2Akttv7nuesqQNAOY0T5MB/DeXvxcyui1/bMXPzdJn6M1wunrun3IF0nX0Bqa5vJiCO6ptn8zlm019Qj/KGCN7bXFQ6dvABbVXNOY2L4b2FJ3HVXIMB2v6qn9s9c+N0mzgPcAl9ddy0gk7QccR+vWd2xvH2vYQ3MDfyawrm1+PV28gzbRCMN0THQ9u3/2yOd2EfAF4JW6CxmFucBm4KriFNTlksb8UOSmBn50sWKYjpuB82w/X3c9MTq98LlJOg3YZPvBumsZpT1oPSP5UtsLgG3AmK/pNDXwNwCz2+ZnFcuiZsUwHTcD1/Ufk6lBem7/7KHP7Vjg9GJ4lxuAEyRdW29Jw1oPrLe9639MN9H6AzAmTQ38B4B5kuYWF0HOBJbVXFPjjWaYjoboqf2zlz432+fbnmV7Dq3f6x22P1hzWUOy/RSwTtL8YtGJwJgvhjcy8G3vBM4BbqN1gel7tlfVW9XYSLoe+BkwX9J6SR+vu6YSdg3TcULb09FOrbuoTuvB/TOf2/j6DHCdpIeBtwFfG+uGGnlbZkREEzXyCD8iookS+BERDZHAj4hoiAR+RERDJPAjIhoigR8R0RAJ/IiIhkjgR0Q0xP8DUaPSUqfmnN8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLNhuzZ1d03s"
      },
      "source": [
        "# GRADED FUNCTION: conv_single_step\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
        "    s = np.multiply(a_slice_prev, W)\n",
        "    # Sum over all entries of the volume s.\n",
        "    Z = np.sum(s)\n",
        "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
        "    Z = Z + float(b)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return Z"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NpFVLIcgwG8",
        "outputId": "84e16f0c-d524-4257-bd8d-55dd6bddbaa2"
      },
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = -6.999089450680221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxy3LrA-hCGY"
      },
      "source": [
        "# GRADED FUNCTION: conv_forward\n",
        "\n",
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, \n",
        "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape[0], A_prev.shape[1], A_prev.shape[2], A_prev.shape[3]\n",
        "    \n",
        "    # Retrieve dimensions from W's shape (≈1 line)\n",
        "    (f, f, n_C_prev, n_C) = W.shape[0], W.shape[1], W.shape[2], W.shape[3]\n",
        "    \n",
        "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
        "    stride = hparameters[\"stride\"]\n",
        "    pad = hparameters[\"pad\"]\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
        "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
        "    n_H = int(int(n_H_prev + 2*pad - f)/stride + 1)\n",
        "    n_W = int(int(n_W_prev + 2*pad - f)/stride + 1)\n",
        "    \n",
        "    # Initialize the output volume Z with zeros. (≈1 line)\n",
        "    Z = np.zeros([m, n_H, n_W, n_C])\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):                  # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i]      # Select ith training example's padded activation\n",
        "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
        "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "            vert_start = stride * h\n",
        "            vert_end = vert_start + f\n",
        "            \n",
        "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
        "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = horiz_start + f\n",
        "                \n",
        "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
        "                                        \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
        "                    a_slice_prev = A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
        "                    weights = W[:, :, :, c]\n",
        "                    biases = b[:, :, :, c]\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
        "                                        \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgrIoitK4kz3",
        "outputId": "3dad4785-7fd7-4e4c-f277-6da2f0a6803d"
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,5,7,4)\n",
        "W = np.random.randn(3,3,4,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 1,\n",
        "               \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\\n\", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\\n\", Z[3,2,1])\n",
        "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z's mean =\n",
            " 0.6923608807576933\n",
            "Z[3,2,1] =\n",
            " [-1.28912231  2.27650251  6.61941931  0.95527176  8.25132576  2.31329639\n",
            " 13.00689405  2.34576051]\n",
            "cache_conv[0][1][2][3] =\n",
            " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4BPAQC56qvA"
      },
      "source": [
        "# GRADED FUNCTION: pool_forward\n",
        "\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the forward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "            vert_start = stride * h \n",
        "            vert_end = vert_start + f\n",
        "            \n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = horiz_start + f\n",
        "                \n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                    a_prev_slice = A_prev[i]\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. \n",
        "                    # Use an if statement to differentiate the modes. \n",
        "                    # Use np.max and np.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice[vert_start:vert_end, horiz_start:horiz_end, c])\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice[vert_start:vert_end, horiz_start:horiz_end, c])\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIwWNzwK6sB1",
        "outputId": "7362bec3-a672-4319-9991-33757451b335"
      },
      "source": [
        "\n",
        "# Case 1: stride of 1\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 1, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A =\n",
            " [[[[1.74481176 0.90159072 1.65980218]\n",
            "   [1.74481176 1.46210794 1.65980218]\n",
            "   [1.74481176 1.6924546  1.65980218]]\n",
            "\n",
            "  [[1.14472371 0.90159072 2.10025514]\n",
            "   [1.14472371 0.90159072 1.65980218]\n",
            "   [1.14472371 1.6924546  1.65980218]]\n",
            "\n",
            "  [[1.13162939 1.51981682 2.18557541]\n",
            "   [1.13162939 1.51981682 2.18557541]\n",
            "   [1.13162939 1.6924546  2.18557541]]]\n",
            "\n",
            "\n",
            " [[[1.19891788 0.84616065 0.82797464]\n",
            "   [0.69803203 0.84616065 1.2245077 ]\n",
            "   [0.69803203 1.12141771 1.2245077 ]]\n",
            "\n",
            "  [[1.96710175 0.84616065 1.27375593]\n",
            "   [1.96710175 0.84616065 1.23616403]\n",
            "   [1.62765075 1.12141771 1.2245077 ]]\n",
            "\n",
            "  [[1.96710175 0.86888616 1.27375593]\n",
            "   [1.96710175 0.86888616 1.23616403]\n",
            "   [1.62765075 1.12141771 0.79280687]]]]\n",
            "\n",
            "mode = average\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A =\n",
            " [[[[-3.01046719e-02 -3.24021315e-03 -3.36298859e-01]\n",
            "   [ 1.43310483e-01  1.93146751e-01 -4.44905196e-01]\n",
            "   [ 1.28934436e-01  2.22428468e-01  1.25067597e-01]]\n",
            "\n",
            "  [[-3.81801899e-01  1.59993515e-02  1.70562706e-01]\n",
            "   [ 4.73707165e-02  2.59244658e-02  9.20338402e-02]\n",
            "   [ 3.97048605e-02  1.57189094e-01  3.45302489e-01]]\n",
            "\n",
            "  [[-3.82680519e-01  2.32579951e-01  6.25997903e-01]\n",
            "   [-2.47157416e-01 -3.48524998e-04  3.50539717e-01]\n",
            "   [-9.52551510e-02  2.68511000e-01  4.66056368e-01]]]\n",
            "\n",
            "\n",
            " [[[-1.73134159e-01  3.23771981e-01 -3.43175716e-01]\n",
            "   [ 3.80634669e-02  7.26706274e-02 -2.30268958e-01]\n",
            "   [ 2.03009393e-02  1.41414785e-01 -1.23158476e-02]]\n",
            "\n",
            "  [[ 4.44976963e-01 -2.61694592e-03 -3.10403073e-01]\n",
            "   [ 5.08114737e-01 -2.34937338e-01 -2.39611830e-01]\n",
            "   [ 1.18726772e-01  1.72552294e-01 -2.21121966e-01]]\n",
            "\n",
            "  [[ 4.29449255e-01  8.44699612e-02 -2.72909051e-01]\n",
            "   [ 6.76351685e-01 -1.20138225e-01 -2.44076712e-01]\n",
            "   [ 1.50774518e-01  2.89111751e-01  1.23238536e-03]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIu2mn5i6xDV",
        "outputId": "4eca9223-b2fe-406c-e4d8-9b9ddb75bafc"
      },
      "source": [
        "# Case 2: stride of 2\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)\n",
        "print()\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A =\\n\", A)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A =\n",
            " [[[[1.74481176 0.90159072 1.65980218]\n",
            "   [1.74481176 1.6924546  1.65980218]]\n",
            "\n",
            "  [[1.13162939 1.51981682 2.18557541]\n",
            "   [1.13162939 1.6924546  2.18557541]]]\n",
            "\n",
            "\n",
            " [[[1.19891788 0.84616065 0.82797464]\n",
            "   [0.69803203 1.12141771 1.2245077 ]]\n",
            "\n",
            "  [[1.96710175 0.86888616 1.27375593]\n",
            "   [1.62765075 1.12141771 0.79280687]]]]\n",
            "\n",
            "mode = average\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A =\n",
            " [[[[-0.03010467 -0.00324021 -0.33629886]\n",
            "   [ 0.12893444  0.22242847  0.1250676 ]]\n",
            "\n",
            "  [[-0.38268052  0.23257995  0.6259979 ]\n",
            "   [-0.09525515  0.268511    0.46605637]]]\n",
            "\n",
            "\n",
            " [[[-0.17313416  0.32377198 -0.34317572]\n",
            "   [ 0.02030094  0.14141479 -0.01231585]]\n",
            "\n",
            "  [[ 0.42944926  0.08446996 -0.27290905]\n",
            "   [ 0.15077452  0.28911175  0.00123239]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aneg9nNM60mj"
      },
      "source": [
        "def conv_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
        "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
        "          numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
        "          numpy array of shape (1, 1, 1, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve information from \"cache\"\n",
        "    (A_prev, W, b, hparameters) = None\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = None\n",
        "    \n",
        "    # Retrieve dimensions from W's shape\n",
        "    (f, f, n_C_prev, n_C) = None\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = None\n",
        "    pad = None\n",
        "    \n",
        "    # Retrieve dimensions from dZ's shape\n",
        "    (m, n_H, n_W, n_C) = None\n",
        "    \n",
        "    # Initialize dA_prev, dW, db with the correct shapes\n",
        "    dA_prev = None                           \n",
        "    dW = None\n",
        "    db = None\n",
        "\n",
        "    # Pad A_prev and dA_prev\n",
        "    A_prev_pad = None\n",
        "    dA_prev_pad = None\n",
        "    \n",
        "    for i in range(None):                       # loop over the training examples\n",
        "        \n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\n",
        "        a_prev_pad = None\n",
        "        da_prev_pad = None\n",
        "        \n",
        "        for h in range(None):                   # loop over vertical axis of the output volume\n",
        "            for w in range(None):               # loop over horizontal axis of the output volume\n",
        "                for c in range(None):           # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = None\n",
        "                    vert_end = None\n",
        "                    horiz_start = None\n",
        "                    horiz_end = None\n",
        "                    \n",
        "                    # Use the corners to define the slice from a_prev_pad\n",
        "                    a_slice = None\n",
        "\n",
        "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += None\n",
        "                    dW[:,:,:,c] += None\n",
        "                    db[:,:,:,c] += None\n",
        "                    \n",
        "        # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
        "        dA_prev[i, :, :, :] = None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "LgPxvlPn6863",
        "outputId": "5e859e51-8a73-47d1-f690-15c1e5bd75ae"
      },
      "source": [
        "# We'll run conv_forward to initialize the 'Z' and 'cache_conv\",\n",
        "# which we'll use to test the conv_backward function\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10,4,4,3)\n",
        "W = np.random.randn(2,2,3,8)\n",
        "b = np.random.randn(1,1,1,8)\n",
        "hparameters = {\"pad\" : 2,\n",
        "               \"stride\": 2}\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "\n",
        "# Test conv_backward\n",
        "dA, dW, db = conv_backward(Z, cache_conv)\n",
        "print(\"dA_mean =\", np.mean(dA))\n",
        "print(\"dW_mean =\", np.mean(dW))\n",
        "print(\"db_mean =\", np.mean(db))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a120e4a9d199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Test conv_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dA_mean =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dW_mean =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8c854916b0cf>\u001b[0m in \u001b[0;36mconv_backward\u001b[0;34m(dZ, cache)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m### START CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Retrieve information from \"cache\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Retrieve dimensions from A_prev's shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbdbDLW07QG4"
      },
      "source": [
        "\n",
        "def create_mask_from_window(x):\n",
        "    \"\"\"\n",
        "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- Array of shape (f, f)\n",
        "    \n",
        "    Returns:\n",
        "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    mask = None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return mask"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKnB7IuP7Rdw",
        "outputId": "a8c3c9be-b8e9-4c3e-ca0e-5ef67f3b8ac0"
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(2,3)\n",
        "mask = create_mask_from_window(x)\n",
        "print('x = ', x)\n",
        "print(\"mask = \", mask)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
            " [-1.07296862  0.86540763 -2.3015387 ]]\n",
            "mask =  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQi4dkz57XFQ"
      },
      "source": [
        "def distribute_value(dz, shape):\n",
        "    \"\"\"\n",
        "    Distributes the input value in the matrix of dimension shape\n",
        "    \n",
        "    Arguments:\n",
        "    dz -- input scalar\n",
        "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
        "    \n",
        "    Returns:\n",
        "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from shape (≈1 line)\n",
        "    (n_H, n_W) = None\n",
        "    \n",
        "    # Compute the value to distribute on the matrix (≈1 line)\n",
        "    average = None\n",
        "    \n",
        "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
        "    a = None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return a"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "w1qNfpJB7bUV",
        "outputId": "324de4f9-fc9c-40f0-f934-1954ba3718ca"
      },
      "source": [
        "a = distribute_value(2, (2,2))\n",
        "print('distributed value =', a)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ab013c047d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distributed value ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-24840a2ee504>\u001b[0m in \u001b[0;36mdistribute_value\u001b[0;34m(dz, shape)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m### START CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Retrieve dimensions from shape (≈1 line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mn_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_W\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Compute the value to distribute on the matrix (≈1 line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TQ1DJC77gST"
      },
      "source": [
        "def pool_backward(dA, cache, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the backward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
        "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Retrieve information from cache (≈1 line)\n",
        "    (A_prev, hparameters) = None\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
        "    stride = None\n",
        "    f = None\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = None\n",
        "    m, n_H, n_W, n_C = None\n",
        "    \n",
        "    # Initialize dA_prev with zeros (≈1 line)\n",
        "    dA_prev = None\n",
        "    \n",
        "    for i in range(None):                       # loop over the training examples\n",
        "        \n",
        "        # select training example from A_prev (≈1 line)\n",
        "        a_prev = None\n",
        "        \n",
        "        for h in range(None):                   # loop on the vertical axis\n",
        "            for w in range(None):               # loop on the horizontal axis\n",
        "                for c in range(None):           # loop over the channels (depth)\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = None\n",
        "                    vert_end = None\n",
        "                    horiz_start = None\n",
        "                    horiz_end = None\n",
        "                    \n",
        "                    # Compute the backward propagation in both modes.\n",
        "                    if mode == \"max\":\n",
        "                        \n",
        "                        # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
        "                        a_prev_slice = None\n",
        "                        # Create the mask from a_prev_slice (≈1 line)\n",
        "                        mask = None\n",
        "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += None\n",
        "                        \n",
        "                    elif mode == \"average\":\n",
        "                        \n",
        "                        # Get the value a from dA (≈1 line)\n",
        "                        da = None\n",
        "                        # Define the shape of the filter as fxf (≈1 line)\n",
        "                        shape = None\n",
        "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += None\n",
        "                        \n",
        "    ### END CODE ###\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == A_prev.shape)\n",
        "    \n",
        "    return dA_prev"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "RoXveu347l4f",
        "outputId": "c115bb72-be85-42bd-f6e7-6300345fb77a"
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(5, 5, 3, 2)\n",
        "hparameters = {\"stride\" : 1, \"f\": 2}\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "dA = np.random.randn(5, 4, 2, 2)\n",
        "\n",
        "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
        "print(\"mode = max\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
        "print()\n",
        "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3a50d76fd6e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode = max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean of dA = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-e0c89c102b0a>\u001b[0m in \u001b[0;36mpool_backward\u001b[0;34m(dA, cache, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Retrieve information from cache (≈1 line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Retrieve hyperparameters from \"hparameters\" (≈2 lines)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    }
  ]
}